{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import .py files\n",
    "import os\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import json\n",
    "# import train_model\n",
    "# import generate_synthetic\n",
    "# import train_classifier\n",
    "# import test_imgs\n",
    "import split_dataset as split\n",
    "import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_home = \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation\"\n",
    "path_models = path_home + \"/models\"\n",
    "path_raw_data = path_home + \"/data/mnist_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "Train Size: [1000, 2000, 3000]\n",
      "Generation Size: [500, 1000, 1500]\n",
      "Synthetic/Real Ratio: 0.5\n",
      "StyleGAN2-ADA Training Cutoff: 5000\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# set parameters for which train_size, gen_size, synthetic/real ratio, GAN train cutoff\n",
    "# set initial dir for experiments\n",
    "\n",
    "# Set parameters as lists of integer values\n",
    "seed = 42\n",
    "train_sizes = [1000, 2000, 3000]  # List of different training sizes\n",
    "gen_sizes = [500, 1000, 1500]      # List of different generation sizes\n",
    "synthetic_real_ratio = 0.5          # Ratio of synthetic to real data\n",
    "gan_train_cutoff = 5000             # Number of GAN training iterations before switching\n",
    "train_ratio = 0.8\n",
    "\n",
    "\n",
    "# Print out the configured parameters for verification\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"Train Size: {train_sizes}\")\n",
    "print(f\"Generation Size: {gen_sizes}\")\n",
    "print(f\"Synthetic/Real Ratio: {synthetic_real_ratio}\")\n",
    "print(f\"StyleGAN2-ADA Training Cutoff: {gan_train_cutoff}\")\n",
    "# print(f\"Experiment Run Directory: {experiment_run_dir}\")\n",
    "print(\"-\" * 40)  # Separator for clarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use preprocessing.ipynb to create a proper dataset\n",
    "# Distribute files to relevant subfolders + create JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting data: 100%|██████████| 10/10 [00:00<00:00, 245.97class/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data statistics:\n",
      "Total number of samples: 47995\n",
      "label\n",
      "0    4738\n",
      "1    5393\n",
      "2    4766\n",
      "3    4904\n",
      "4    4673\n",
      "5    4336\n",
      "6    4734\n",
      "7    5012\n",
      "8    4680\n",
      "9    4759\n",
      "Name: count, dtype: int64\n",
      "Test data statistics:\n",
      "Total number of samples: 12005\n",
      "label\n",
      "0    1185\n",
      "1    1349\n",
      "2    1192\n",
      "3    1227\n",
      "4    1169\n",
      "5    1085\n",
      "6    1184\n",
      "7    1253\n",
      "8    1171\n",
      "9    1190\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# split into train/test\n",
    "\n",
    "full_json = path_home + '/data/dataset_full.json'\n",
    "\n",
    "# split into test/train subsets\n",
    "train_json = full_json\n",
    "\n",
    "train_df, test_df = split.split_train_test(train_json, train_ratio, seed=seed)\n",
    "\n",
    "train_output_file = f\"{path_raw_data}/train_data.json\"\n",
    "test_output_file = f\"{path_raw_data}/test_data.json\"\n",
    "\n",
    "split.save_data(train_df, train_output_file)\n",
    "split.save_data(test_df, test_output_file)\n",
    "\n",
    "split.print_class_distribution(train_df, \"Train\")\n",
    "split.print_class_distribution(test_df, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train MLP/CNN classifier, test for benchmark using test_imgs.py\n",
    "# V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subsetting classes: 100%|██████████| 10/10 [00:00<00:00, 1208.91class/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset_df, path_raw_data, path_model_images:  /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/data/mnist_images /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/models/model_0.0K/images\n",
      "Starting to generate labels JSON file...\n",
      "Base directory: /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/models/model_0.0K/images\n",
      "Generated labels JSON file with 50 entries.\n",
      "Creating dataset for model_0.0K...\n",
      "\n",
      "Creating dataset with command: python /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/stylegan2-ada-pytorch/dataset_tool.py --source /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/models/model_0.0K/images --dest /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/models/model_0.0K/dataset\n",
      "Loading labels from /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/models/model_0.0K/images/dataset.json\n",
      "opened /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/models/model_0.0K/images/dataset.json\n",
      "labels found\n",
      "Before the loop:\n",
      "Labels: [['9/9_41102.png', 9], ['9/9_27732.png', 9], ['9/9_30758.png', 9], ['9/9_40440.png', 9], ['9/9_4378.png', 9], ['0/0_38055.png', 0], ['0/0_2473.png', 0], ['0/0_10204.png', 0], ['0/0_47887.png', 0], ['0/0_20010.png', 0], ['7/7_3494.png', 7], ['7/7_6666.png', 7], ['7/7_56359.png', 7], ['7/7_59524.png', 7], ['7/7_47682.png', 7], ['6/6_30142.png', 6], ['6/6_52263.png', 6], ['6/6_58415.png', 6], ['6/6_20343.png', 6], ['6/6_7490.png', 6], ['1/1_20686.png', 1], ['1/1_27558.png', 1], ['1/1_38928.png', 1], ['1/1_58189.png', 1], ['1/1_33298.png', 1], ['8/8_6390.png', 8], ['8/8_18450.png', 8], ['8/8_36192.png', 8], ['8/8_55026.png', 8], ['8/8_32742.png', 8], ['4/4_7703.png', 4], ['4/4_20599.png', 4], ['4/4_23713.png', 4], ['4/4_55828.png', 4], ['4/4_11113.png', 4], ['3/3_43562.png', 3], ['3/3_39871.png', 3], ['3/3_36078.png', 3], ['3/3_695.png', 3], ['3/3_50717.png', 3], ['2/2_57388.png', 2], ['2/2_3930.png', 2], ['2/2_50251.png', 2], ['2/2_39921.png', 2], ['2/2_56264.png', 2], ['5/5_41980.png', 5], ['5/5_16737.png', 5], ['5/5_45963.png', 5], ['5/5_21115.png', 5], ['5/5_23105.png', 5]]\n",
      "Starting the loop...\n",
      "After the loop:\n",
      "Labels: {'9/9_41102.png': 9, '9/9_27732.png': 9, '9/9_30758.png': 9, '9/9_40440.png': 9, '9/9_4378.png': 9, '0/0_38055.png': 0, '0/0_2473.png': 0, '0/0_10204.png': 0, '0/0_47887.png': 0, '0/0_20010.png': 0, '7/7_3494.png': 7, '7/7_6666.png': 7, '7/7_56359.png': 7, '7/7_59524.png': 7, '7/7_47682.png': 7, '6/6_30142.png': 6, '6/6_52263.png': 6, '6/6_58415.png': 6, '6/6_20343.png': 6, '6/6_7490.png': 6, '1/1_20686.png': 1, '1/1_27558.png': 1, '1/1_38928.png': 1, '1/1_58189.png': 1, '1/1_33298.png': 1, '8/8_6390.png': 8, '8/8_18450.png': 8, '8/8_36192.png': 8, '8/8_55026.png': 8, '8/8_32742.png': 8, '4/4_7703.png': 4, '4/4_20599.png': 4, '4/4_23713.png': 4, '4/4_55828.png': 4, '4/4_11113.png': 4, '3/3_43562.png': 3, '3/3_39871.png': 3, '3/3_36078.png': 3, '3/3_695.png': 3, '3/3_50717.png': 3, '2/2_57388.png': 2, '2/2_3930.png': 2, '2/2_50251.png': 2, '2/2_39921.png': 2, '2/2_56264.png': 2, '5/5_41980.png': 5, '5/5_16737.png': 5, '5/5_45963.png': 5, '5/5_21115.png': 5, '5/5_23105.png': 5}\n",
      "Error: --dest folder must be empty\n",
      "Error while running the command: Command 'python /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/stylegan2-ada-pytorch/dataset_tool.py --source /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/models/model_0.0K/images --dest /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/models/model_0.0K/dataset' returned non-zero exit status 1.\n",
      "\n",
      "Training model_0.0K...\n",
      "Running command: python /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/stylegan2-ada-pytorch/train.py --snap 10 --cond=1 --outdir /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/models/model_0.0K/experiments --data /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/models/model_0.0K/dataset\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 10,\n",
      "  \"network_snapshot_ticks\": 10,\n",
      "  \"metrics\": [\n",
      "    \"fid50k_full\"\n",
      "  ],\n",
      "  \"random_seed\": 0,\n",
      "  \"training_set_kwargs\": {\n",
      "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
      "    \"path\": \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/models/model_0.0K/dataset\",\n",
      "    \"use_labels\": true,\n",
      "    \"max_size\": 50,\n",
      "    \"xflip\": false,\n",
      "    \"resolution\": 32\n",
      "  },\n",
      "  \"data_loader_kwargs\": {\n",
      "    \"pin_memory\": true,\n",
      "    \"num_workers\": 3,\n",
      "    \"prefetch_factor\": 2\n",
      "  },\n",
      "  \"G_kwargs\": {\n",
      "    \"class_name\": \"training.networks.Generator\",\n",
      "    \"z_dim\": 512,\n",
      "    \"w_dim\": 512,\n",
      "    \"mapping_kwargs\": {\n",
      "      \"num_layers\": 2\n",
      "    },\n",
      "    \"synthesis_kwargs\": {\n",
      "      \"channel_base\": 16384,\n",
      "      \"channel_max\": 512,\n",
      "      \"num_fp16_res\": 4,\n",
      "      \"conv_clamp\": 256\n",
      "    }\n",
      "  },\n",
      "  \"D_kwargs\": {\n",
      "    \"class_name\": \"training.networks.Discriminator\",\n",
      "    \"block_kwargs\": {},\n",
      "    \"mapping_kwargs\": {},\n",
      "    \"epilogue_kwargs\": {\n",
      "      \"mbstd_group_size\": 4\n",
      "    },\n",
      "    \"channel_base\": 16384,\n",
      "    \"channel_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"lr\": 0.0025,\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08\n",
      "  },\n",
      "  \"D_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"lr\": 0.0025,\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08\n",
      "  },\n",
      "  \"loss_kwargs\": {\n",
      "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
      "    \"r1_gamma\": 0.0064\n",
      "  },\n",
      "  \"total_kimg\": 25000,\n",
      "  \"batch_size\": 32,\n",
      "  \"batch_gpu\": 32,\n",
      "  \"ema_kimg\": 10.0,\n",
      "  \"ema_rampup\": 0.05,\n",
      "  \"ada_target\": 0.6,\n",
      "  \"augment_kwargs\": {\n",
      "    \"class_name\": \"training.augment.AugmentPipe\",\n",
      "    \"xflip\": 1,\n",
      "    \"rotate90\": 1,\n",
      "    \"xint\": 1,\n",
      "    \"scale\": 1,\n",
      "    \"rotate\": 1,\n",
      "    \"aniso\": 1,\n",
      "    \"xfrac\": 1,\n",
      "    \"brightness\": 1,\n",
      "    \"contrast\": 1,\n",
      "    \"lumaflip\": 1,\n",
      "    \"hue\": 1,\n",
      "    \"saturation\": 1\n",
      "  },\n",
      "  \"run_dir\": \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/models/model_0.0K/experiments/00000-dataset-cond-auto1\"\n",
      "}\n",
      "\n",
      "Output directory:   /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/models/model_0.0K/experiments/00000-dataset-cond-auto1\n",
      "Training data:      /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/models/model_0.0K/dataset\n",
      "Training duration:  25000 kimg\n",
      "Number of GPUs:     1\n",
      "Number of images:   50\n",
      "Image resolution:   32\n",
      "Conditional model:  True\n",
      "Dataset x-flips:    False\n",
      "\n",
      "Creating output directory...\n",
      "Launching processes...\n",
      "Loading training set...\n",
      "/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/.venv/lib/python3.10/site-packages/torch/utils/data/sampler.py:65: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
      "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
      "\n",
      "Num images:  50\n",
      "Image shape: [3, 32, 32]\n",
      "Label shape: [10]\n",
      "\n",
      "Constructing networks...\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/stylegan2-ada-pytorch/train.py\", line 538, in <module>\n",
      "    main() # pylint: disable=no-value-for-parameter\n",
      "  File \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/.venv/lib/python3.10/site-packages/click/core.py\", line 1157, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/.venv/lib/python3.10/site-packages/click/core.py\", line 1078, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/.venv/lib/python3.10/site-packages/click/core.py\", line 1434, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/.venv/lib/python3.10/site-packages/click/core.py\", line 783, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/.venv/lib/python3.10/site-packages/click/decorators.py\", line 33, in new_func\n",
      "    return f(get_current_context(), *args, **kwargs)\n",
      "  File \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/stylegan2-ada-pytorch/train.py\", line 531, in main\n",
      "    subprocess_fn(rank=0, args=args, temp_dir=temp_dir)\n",
      "  File \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/stylegan2-ada-pytorch/train.py\", line 383, in subprocess_fn\n",
      "    training_loop.training_loop(rank=rank, **args)\n",
      "  File \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/stylegan2-ada-pytorch/training/training_loop.py\", line 150, in training_loop\n",
      "    G = dnnlib.util.construct_class_by_name(**G_kwargs, **common_kwargs).train().requires_grad_(False).to(device) # subclass of torch.nn.Module\n",
      "  File \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1174, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 780, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 805, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1160, in convert\n",
      "    return t.to(\n",
      "  File \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/.venv/lib/python3.10/site-packages/torch/cuda/__init__.py\", line 305, in _lazy_init\n",
      "    raise AssertionError(\"Torch not compiled with CUDA enabled\")\n",
      "AssertionError: Torch not compiled with CUDA enabled\n",
      "Exception ignored in atexit callback: <function _exit_function at 0x115bd8c10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/util.py\", line 357, in _exit_function\n",
      "    p.join()\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/popen_fork.py\", line 43, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/popen_fork.py\", line 27, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "  File \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py\", line 67, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 39900) is killed by signal: Terminated: 15. \n",
      "Error while running the command: Command 'python /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/stylegan2-ada-pytorch/train.py --snap 10 --cond=1 --outdir /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/models/model_0.0K/experiments --data /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/models/model_0.0K/dataset' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "# for loop: create dir, create dataset, train model, generate syn-images, test\n",
    "\n",
    "# from random import seed\n",
    "train_json = path_raw_data + '/train_data.json'\n",
    "# input_file = path_home + '/data/dataset.json'\n",
    "\n",
    "# train_sizes = [1000]\n",
    "train_sizes = [5]\n",
    "for train_size in train_sizes:\n",
    "    # Create a name for the subset and the model\n",
    "    model_name = f\"model_{float(train_size) // 1000}K\"\n",
    "    path_model = os.path.join(path_models, model_name)\n",
    "    path_experiments = os.path.join(path_model, 'experiments')\n",
    "    path_dataset = os.path.join(path_model, 'dataset')\n",
    "    _,_,path_model_images = split.open_folders(model_name, path_model)\n",
    "    \n",
    "    subset_df = split.subset_data(train_json, train_size, seed)\n",
    "    # print('subset_df: ',subset_df)\n",
    "    print('subset_df, path_raw_data, path_model_images: ', path_raw_data, path_model_images)\n",
    "    split.copy_images_to_model_and_dataset(subset_df, path_raw_data, path_model_images)\n",
    "    path_subset_json = f\"{path_model}/dataset_subset_size_{train_size}_seed_{seed}.json\"\n",
    "    split.save_data(subset_df, path_subset_json)\n",
    "\n",
    "\n",
    "    split.distribute_files_to_label_dirs(path_model_images)\n",
    "\n",
    "    split.generate_labels_json(path_model_images, path_model, \"dataset_full.json\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    print(f\"Creating dataset for {model_name}...\")\n",
    "    # print('path_home: '+ path_home)\n",
    "    # print('raw_data: '+ path_raw_data)\n",
    "    # print('model_dir: '+ path_model+'/dataset')\n",
    "    print()\n",
    "    train_model.create_dataset(path_home, path_model_images, path_dataset)\n",
    "\n",
    "    print()\n",
    "    print(f\"Training {model_name}...\")\n",
    "    train_model.run_stylegan_training(path_home, path_experiments, path_dataset, snap=10)\n",
    "    \n",
    "\n",
    "    # for gen_size in gen_sizes:\n",
    "    #     print(f\"Generating synthetic images for {model_name}...\")\n",
    "    #     train.generate_stylegan_images(path_home, model_dir + '/experiments/.....', model_dir + '/experiments/...' ,gen_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def remove_all_files_in_dir(directory):\n",
    "    # Get all files in the directory (excluding subdirectories)\n",
    "    files = glob.glob(os.path.join(directory, '*')) + glob.glob(os.path.join(directory, '.*'))\n",
    "\n",
    "    for file in files:\n",
    "        # if os.path.isfile(file):  # Only delete files, not directories\n",
    "        print(f\"Removing file: {file}\")  # Optional: to show which files are being deleted\n",
    "        os.remove(file)\n",
    "\n",
    "# Usage example\n",
    "dir_path = \"./models/model_1K/dataset\"\n",
    "remove_all_files_in_dir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest = path_model + '/dataset'\n",
    "os.path.isdir(dest)\n",
    "os.listdir(dest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results - relevant metric: avg/class accuracy, f1, precision, recall, AUC-ROC...\n",
    "# graph/tabular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete datasets (keep logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image_folder(source_dir, *, max_images=100000):\n",
    "    input_images = [str(f) for f in sorted(Path(source_dir).rglob('*')) if is_image_ext(f) and os.path.isfile(f)]\n",
    "\n",
    "    # Load labels.\n",
    "    labels = {}\n",
    "    meta_fname = os.path.join(source_dir, 'dataset.json')\n",
    "    if os.path.isfile(meta_fname):\n",
    "        with open(meta_fname, 'r') as file:\n",
    "            labels = json.load(file)['labels']\n",
    "            if labels is not None:\n",
    "                labels = { x[0]: x[1] for x in labels }\n",
    "            else:\n",
    "                labels = {}\n",
    "\n",
    "\n",
    "    def iterate_images():\n",
    "        for idx, fname in enumerate(input_images):\n",
    "            arch_fname = os.path.relpath(fname, source_dir)\n",
    "            arch_fname = arch_fname.replace('\\\\', '/')\n",
    "            img = np.array(PIL.Image.open(fname))\n",
    "            yield dict(img=img, label=labels.get(arch_fname))\n",
    "            if idx >= max_idx-1:\n",
    "                break\n",
    "    return max_idx, iterate_images()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
