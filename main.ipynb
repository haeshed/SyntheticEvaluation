{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import .py files\n",
    "import os\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import json\n",
    "# import train_model\n",
    "# import generate_synthetic\n",
    "# import train_classifier\n",
    "# import test_imgs\n",
    "import split_dataset as split\n",
    "import train_model\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_home = '/home/pathorad3090/Documents/Hadar/SyntheticEvaluation'\n",
    "path_models = path_home + \"/models\"\n",
    "path_raw_data = path_home + \"/data/mnist_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "Train Size: [1000, 5000, 10000]\n",
      "Generation Size: [500, 1000, 1500]\n",
      "Synthetic/Real Ratio: 0.5\n",
      "StyleGAN2-ADA Training Cutoff: 5000\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# set parameters for which train_size, gen_size, synthetic/real ratio, GAN train cutoff\n",
    "# set initial dir for experiments\n",
    "\n",
    "# Set parameters as lists of integer values\n",
    "seed = 42\n",
    "train_sizes = [1000, 5000, 10000]  # List of different training sizes\n",
    "gen_sizes = [500, 1000, 1500]      # List of different generation sizes\n",
    "synthetic_real_ratio = 0.5          # Ratio of synthetic to real data\n",
    "gan_train_cutoff = 5000             # Number of GAN training iterations before switching\n",
    "train_ratio = 0.8\n",
    "\n",
    "\n",
    "# Print out the configured parameters for verification\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"Train Size: {train_sizes}\")\n",
    "print(f\"Generation Size: {gen_sizes}\")\n",
    "print(f\"Synthetic/Real Ratio: {synthetic_real_ratio}\")\n",
    "print(f\"StyleGAN2-ADA Training Cutoff: {gan_train_cutoff}\")\n",
    "# print(f\"Experiment Run Directory: {experiment_run_dir}\")\n",
    "print(\"-\" * 40)  # Separator for clarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use preprocessing.ipynb to create a proper dataset\n",
    "# Distribute files to relevant subfolders + create JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting data: 100%|██████████| 10/10 [00:00<00:00, 111.18class/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data statistics:\n",
      "Total number of samples: 47995\n",
      "0    4738\n",
      "1    5393\n",
      "2    4766\n",
      "3    4904\n",
      "4    4673\n",
      "5    4336\n",
      "6    4734\n",
      "7    5012\n",
      "8    4680\n",
      "9    4759\n",
      "Name: label, dtype: int64\n",
      "Test data statistics:\n",
      "Total number of samples: 12005\n",
      "0    1185\n",
      "1    1349\n",
      "2    1192\n",
      "3    1227\n",
      "4    1169\n",
      "5    1085\n",
      "6    1184\n",
      "7    1253\n",
      "8    1171\n",
      "9    1190\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# split into train/test\n",
    "\n",
    "full_json = path_home + '/data/dataset_full.json'\n",
    "\n",
    "# split into test/train subsets\n",
    "train_json = full_json\n",
    "\n",
    "train_df, test_df = split.split_train_test(train_json, train_ratio, seed=seed)\n",
    "\n",
    "train_output_file = f\"{path_raw_data}/train_data.json\"\n",
    "test_output_file = f\"{path_raw_data}/test_data.json\"\n",
    "\n",
    "split.save_data(train_df, train_output_file)\n",
    "split.save_data(test_df, test_output_file)\n",
    "\n",
    "split.print_class_distribution(train_df, \"Train\")\n",
    "split.print_class_distribution(test_df, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train MLP/CNN classifier, test for benchmark using test_imgs.py\n",
    "# V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export MKL_SERVICE_FORCE_INTEL=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subsetting classes: 100%|██████████| 10/10 [00:00<00:00, 2032.03class/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset_df, path_raw_data, path_model_images:  /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_1.0K_20241103_15-02/images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to generate labels JSON file...\n",
      "Base directory: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_1.0K_20241103_15-02/images\n",
      "Processed 10000 files...\n",
      "Generated labels JSON file with 10000 entries.\n",
      "Creating dataset for model_1.0K_20241103_15-02...\n",
      "Creating dataset with command: python /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/dataset_tool.py --source /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_1.0K_20241103_15-02/images --dest /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_1.0K_20241103_15-02/dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/dataset_tool.py:205: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  resample = { 'box': PIL.Image.BOX, 'lanczos': PIL.Image.LANCZOS }[resize_filter]\n",
      "/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/dataset_tool.py:205: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  resample = { 'box': PIL.Image.BOX, 'lanczos': PIL.Image.LANCZOS }[resize_filter]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 5889.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model_1.0K_20241103_15-02...\n",
      "Running command: python /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/train.py --snap 10 --cond=1 --outdir /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_1.0K_20241103_15-02/experiments --data /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_1.0K_20241103_15-02/dataset --kimg=1000\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 10,\n",
      "  \"network_snapshot_ticks\": 10,\n",
      "  \"metrics\": [\n",
      "    \"fid50k_full\"\n",
      "  ],\n",
      "  \"random_seed\": 0,\n",
      "  \"training_set_kwargs\": {\n",
      "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
      "    \"path\": \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_1.0K_20241103_15-02/dataset\",\n",
      "    \"use_labels\": true,\n",
      "    \"max_size\": 10000,\n",
      "    \"xflip\": false,\n",
      "    \"resolution\": 32\n",
      "  },\n",
      "  \"data_loader_kwargs\": {\n",
      "    \"pin_memory\": true,\n",
      "    \"num_workers\": 3,\n",
      "    \"prefetch_factor\": 2\n",
      "  },\n",
      "  \"G_kwargs\": {\n",
      "    \"class_name\": \"training.networks.Generator\",\n",
      "    \"z_dim\": 512,\n",
      "    \"w_dim\": 512,\n",
      "    \"mapping_kwargs\": {\n",
      "      \"num_layers\": 2\n",
      "    },\n",
      "    \"synthesis_kwargs\": {\n",
      "      \"channel_base\": 16384,\n",
      "      \"channel_max\": 512,\n",
      "      \"num_fp16_res\": 4,\n",
      "      \"conv_clamp\": 256\n",
      "    }\n",
      "  },\n",
      "  \"D_kwargs\": {\n",
      "    \"class_name\": \"training.networks.Discriminator\",\n",
      "    \"block_kwargs\": {},\n",
      "    \"mapping_kwargs\": {},\n",
      "    \"epilogue_kwargs\": {\n",
      "      \"mbstd_group_size\": 4\n",
      "    },\n",
      "    \"channel_base\": 16384,\n",
      "    \"channel_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"lr\": 0.0025,\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08\n",
      "  },\n",
      "  \"D_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"lr\": 0.0025,\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08\n",
      "  },\n",
      "  \"loss_kwargs\": {\n",
      "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
      "    \"r1_gamma\": 0.0064\n",
      "  },\n",
      "  \"total_kimg\": 1000,\n",
      "  \"batch_size\": 32,\n",
      "  \"batch_gpu\": 32,\n",
      "  \"ema_kimg\": 10.0,\n",
      "  \"ema_rampup\": 0.05,\n",
      "  \"ada_target\": 0.6,\n",
      "  \"augment_kwargs\": {\n",
      "    \"class_name\": \"training.augment.AugmentPipe\",\n",
      "    \"xflip\": 1,\n",
      "    \"rotate90\": 1,\n",
      "    \"xint\": 1,\n",
      "    \"scale\": 1,\n",
      "    \"rotate\": 1,\n",
      "    \"aniso\": 1,\n",
      "    \"xfrac\": 1,\n",
      "    \"brightness\": 1,\n",
      "    \"contrast\": 1,\n",
      "    \"lumaflip\": 1,\n",
      "    \"hue\": 1,\n",
      "    \"saturation\": 1\n",
      "  },\n",
      "  \"run_dir\": \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_1.0K_20241103_15-02/experiments/00000-dataset-cond-auto1-kimg1000\"\n",
      "}\n",
      "\n",
      "Output directory:   /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_1.0K_20241103_15-02/experiments/00000-dataset-cond-auto1-kimg1000\n",
      "Training data:      /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_1.0K_20241103_15-02/dataset\n",
      "Training duration:  1000 kimg\n",
      "Number of GPUs:     1\n",
      "Number of images:   10000\n",
      "Image resolution:   32\n",
      "Conditional model:  True\n",
      "Dataset x-flips:    False\n",
      "\n",
      "Creating output directory...\n",
      "Launching processes...\n",
      "Loading training set...\n",
      "\n",
      "Num images:  10000\n",
      "Image shape: [3, 32, 32]\n",
      "Label shape: [10]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Failed!\n",
      "/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/bias_act.py:50: UserWarning: Failed to build CUDA kernels for bias_act. Falling back to slow reference implementation. Details:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1673, in _run_ninja_build\n",
      "    env=env)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/subprocess.py\", line 512, in run\n",
      "    output=stdout, stderr=stderr)\n",
      "subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/bias_act.py\", line 48, in _init\n",
      "    _plugin = custom_ops.get_plugin('bias_act_plugin', sources=sources, extra_cuda_cflags=['--use_fast_math'])\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/custom_ops.py\", line 110, in get_plugin\n",
      "    torch.utils.cpp_extension.load(name=module_name, verbose=verbose_build, sources=sources, **build_kwargs)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1091, in load\n",
      "    keep_intermediates=keep_intermediates)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1302, in _jit_compile\n",
      "    is_standalone=is_standalone)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1407, in _write_ninja_file_and_build_library\n",
      "    error_prefix=f\"Error building extension '{name}'\")\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1683, in _run_ninja_build\n",
      "    raise RuntimeError(message) from e\n",
      "RuntimeError: Error building extension 'bias_act_plugin': [1/2] /usr/bin/nvcc --generate-dependencies-with-compile --dependency-output bias_act.cuda.o.d -DTORCH_EXTENSION_NAME=bias_act_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/TH -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/THC -isystem /home/pathorad3090/miniconda3/envs/MLH/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' --use_fast_math -std=c++14 -c /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/bias_act.cu -o bias_act.cuda.o \n",
      "FAILED: bias_act.cuda.o \n",
      "/usr/bin/nvcc --generate-dependencies-with-compile --dependency-output bias_act.cuda.o.d -DTORCH_EXTENSION_NAME=bias_act_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/TH -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/THC -isystem /home/pathorad3090/miniconda3/envs/MLH/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' --use_fast_math -std=c++14 -c /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/bias_act.cu -o bias_act.cuda.o \n",
      "/usr/include/c++/11/bits/std_function.h:435:145: error: parameter packs not expanded with ‘...’:\n",
      "  435 |         function(_Functor&& __f)\n",
      "      |                                                                                                                                                 ^ \n",
      "/usr/include/c++/11/bits/std_function.h:435:145: note:         ‘_ArgTypes’\n",
      "/usr/include/c++/11/bits/std_function.h:530:146: error: parameter packs not expanded with ‘...’:\n",
      "  530 |         operator=(_Functor&& __f)\n",
      "      |                                                                                                                                                  ^ \n",
      "/usr/include/c++/11/bits/std_function.h:530:146: note:         ‘_ArgTypes’\n",
      "ninja: build stopped: subcommand failed.\n",
      "\n",
      "\n",
      "  warnings.warn('Failed to build CUDA kernels for bias_act. Falling back to slow reference implementation. Details:\\n\\n' + traceback.format_exc())\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Failed!\n",
      "/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/upfirdn2d.py:34: UserWarning: Failed to build CUDA kernels for upfirdn2d. Falling back to slow reference implementation. Details:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1673, in _run_ninja_build\n",
      "    env=env)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/subprocess.py\", line 512, in run\n",
      "    output=stdout, stderr=stderr)\n",
      "subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/upfirdn2d.py\", line 32, in _init\n",
      "    _plugin = custom_ops.get_plugin('upfirdn2d_plugin', sources=sources, extra_cuda_cflags=['--use_fast_math'])\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/custom_ops.py\", line 110, in get_plugin\n",
      "    torch.utils.cpp_extension.load(name=module_name, verbose=verbose_build, sources=sources, **build_kwargs)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1091, in load\n",
      "    keep_intermediates=keep_intermediates)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1302, in _jit_compile\n",
      "    is_standalone=is_standalone)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1407, in _write_ninja_file_and_build_library\n",
      "    error_prefix=f\"Error building extension '{name}'\")\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1683, in _run_ninja_build\n",
      "    raise RuntimeError(message) from e\n",
      "RuntimeError: Error building extension 'upfirdn2d_plugin': [1/2] /usr/bin/nvcc --generate-dependencies-with-compile --dependency-output upfirdn2d.cuda.o.d -DTORCH_EXTENSION_NAME=upfirdn2d_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/TH -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/THC -isystem /home/pathorad3090/miniconda3/envs/MLH/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' --use_fast_math -std=c++14 -c /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/upfirdn2d.cu -o upfirdn2d.cuda.o \n",
      "FAILED: upfirdn2d.cuda.o \n",
      "/usr/bin/nvcc --generate-dependencies-with-compile --dependency-output upfirdn2d.cuda.o.d -DTORCH_EXTENSION_NAME=upfirdn2d_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/TH -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/THC -isystem /home/pathorad3090/miniconda3/envs/MLH/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' --use_fast_math -std=c++14 -c /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/upfirdn2d.cu -o upfirdn2d.cuda.o \n",
      "/usr/include/c++/11/bits/std_function.h:435:145: error: parameter packs not expanded with ‘...’:\n",
      "  435 |         function(_Functor&& __f)\n",
      "      |                                                                                                                                                 ^ \n",
      "/usr/include/c++/11/bits/std_function.h:435:145: note:         ‘_ArgTypes’\n",
      "/usr/include/c++/11/bits/std_function.h:530:146: error: parameter packs not expanded with ‘...’:\n",
      "  530 |         operator=(_Functor&& __f)\n",
      "      |                                                                                                                                                  ^ \n",
      "/usr/include/c++/11/bits/std_function.h:530:146: note:         ‘_ArgTypes’\n",
      "ninja: build stopped: subcommand failed.\n",
      "\n",
      "\n",
      "  warnings.warn('Failed to build CUDA kernels for upfirdn2d. Falling back to slow reference implementation. Details:\\n\\n' + traceback.format_exc())\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "\n",
      "Generator            Parameters  Buffers  Output shape       Datatype\n",
      "---                  ---         ---      ---                ---     \n",
      "mapping.embed        5632        -        [32, 512]          float32 \n",
      "mapping.fc0          524800      -        [32, 512]          float32 \n",
      "mapping.fc1          262656      -        [32, 512]          float32 \n",
      "mapping              -           512      [32, 8, 512]       float32 \n",
      "synthesis.b4.conv1   2622465     32       [32, 512, 4, 4]    float32 \n",
      "synthesis.b4.torgb   264195      -        [32, 3, 4, 4]      float32 \n",
      "synthesis.b4:0       8192        16       [32, 512, 4, 4]    float32 \n",
      "synthesis.b4:1       -           -        [32, 512, 4, 4]    float32 \n",
      "synthesis.b8.conv0   2622465     80       [32, 512, 8, 8]    float16 \n",
      "synthesis.b8.conv1   2622465     80       [32, 512, 8, 8]    float16 \n",
      "synthesis.b8.torgb   264195      -        [32, 3, 8, 8]      float16 \n",
      "synthesis.b8:0       -           16       [32, 512, 8, 8]    float16 \n",
      "synthesis.b8:1       -           -        [32, 512, 8, 8]    float32 \n",
      "synthesis.b16.conv0  2622465     272      [32, 512, 16, 16]  float16 \n",
      "synthesis.b16.conv1  2622465     272      [32, 512, 16, 16]  float16 \n",
      "synthesis.b16.torgb  264195      -        [32, 3, 16, 16]    float16 \n",
      "synthesis.b16:0      -           16       [32, 512, 16, 16]  float16 \n",
      "synthesis.b16:1      -           -        [32, 512, 16, 16]  float32 \n",
      "synthesis.b32.conv0  2622465     1040     [32, 512, 32, 32]  float16 \n",
      "synthesis.b32.conv1  2622465     1040     [32, 512, 32, 32]  float16 \n",
      "synthesis.b32.torgb  264195      -        [32, 3, 32, 32]    float16 \n",
      "synthesis.b32:0      -           16       [32, 512, 32, 32]  float16 \n",
      "synthesis.b32:1      -           -        [32, 512, 32, 32]  float32 \n",
      "---                  ---         ---      ---                ---     \n",
      "Total                20215315    3392     -                  -       \n",
      "\n",
      "\n",
      "Discriminator  Parameters  Buffers  Output shape       Datatype\n",
      "---            ---         ---      ---                ---     \n",
      "b32.fromrgb    2048        16       [32, 512, 32, 32]  float16 \n",
      "b32.skip       262144      16       [32, 512, 16, 16]  float16 \n",
      "b32.conv0      2359808     16       [32, 512, 32, 32]  float16 \n",
      "b32.conv1      2359808     16       [32, 512, 16, 16]  float16 \n",
      "b32            -           16       [32, 512, 16, 16]  float16 \n",
      "b16.skip       262144      16       [32, 512, 8, 8]    float16 \n",
      "b16.conv0      2359808     16       [32, 512, 16, 16]  float16 \n",
      "b16.conv1      2359808     16       [32, 512, 8, 8]    float16 \n",
      "b16            -           16       [32, 512, 8, 8]    float16 \n",
      "b8.skip        262144      16       [32, 512, 4, 4]    float16 \n",
      "b8.conv0       2359808     16       [32, 512, 8, 8]    float16 \n",
      "b8.conv1       2359808     16       [32, 512, 4, 4]    float16 \n",
      "b8             -           16       [32, 512, 4, 4]    float16 \n",
      "mapping.embed  5632        -        [32, 512]          float32 \n",
      "mapping.fc0    262656      -        [32, 512]          float32 \n",
      "mapping.fc1    262656      -        [32, 512]          float32 \n",
      "mapping.fc2    262656      -        [32, 512]          float32 \n",
      "mapping.fc3    262656      -        [32, 512]          float32 \n",
      "mapping.fc4    262656      -        [32, 512]          float32 \n",
      "mapping.fc5    262656      -        [32, 512]          float32 \n",
      "mapping.fc6    262656      -        [32, 512]          float32 \n",
      "mapping.fc7    262656      -        [32, 512]          float32 \n",
      "b4.mbstd       -           -        [32, 513, 4, 4]    float32 \n",
      "b4.conv        2364416     16       [32, 512, 4, 4]    float32 \n",
      "b4.fc          4194816     -        [32, 512]          float32 \n",
      "b4.out         262656      -        [32, 512]          float32 \n",
      "b4             -           -        [32, 1]            float32 \n",
      "---            ---         ---      ---                ---     \n",
      "Total          23876096    224      -                  -       \n",
      "\n",
      "Setting up augmentation...\n",
      "Distributing across 1 GPUs...\n",
      "Setting up training phases...\n",
      "Exporting sample images...\n",
      "Initializing logs...\n",
      "Skipping tfevents export: No module named 'tensorboard'\n",
      "Training for 1000 kimg...\n",
      "\n",
      "tick 0     kimg 0.0      time 22s          sec/tick 2.6     sec/kimg 81.52   maintenance 18.9   cpumem 4.22   gpumem 11.70  augment 0.000\n",
      "Evaluating metrics...\n"
     ]
    }
   ],
   "source": [
    "# for loop: create dir, create dataset, train model, generate syn-images, test\n",
    "\n",
    "# from random import seed\n",
    "train_json = path_raw_data + '/train_data.json'\n",
    "# input_file = path_home + '/data/dataset.json'\n",
    "\n",
    "\n",
    "\n",
    "# train_sizes = [1000]\n",
    "# train_sizes = [5]\n",
    "for train_size in train_sizes:\n",
    "    # Create a name for the subset and the model\n",
    "    model_name = f\"model_{float(train_size) // 1000}K_{datetime.now().strftime('%Y%m%d_%H-%M')}\"\n",
    "    path_model = os.path.join(path_models, model_name)\n",
    "    path_experiments = os.path.join(path_model, 'experiments')\n",
    "    path_dataset = os.path.join(path_model, 'dataset')\n",
    "    _,_,path_model_images = split.open_folders(model_name, path_model)\n",
    "    \n",
    "    subset_df = split.subset_data(train_json, train_size, seed)\n",
    "    # print('subset_df: ',subset_df)\n",
    "    print('subset_df, path_raw_data, path_model_images: ', path_raw_data, path_model_images)\n",
    "    split.copy_images_to_model_and_dataset(subset_df, path_raw_data, path_model_images)\n",
    "    path_subset_json = f\"{path_model}/dataset_subset_size_{train_size}_seed_{seed}.json\"\n",
    "    split.save_data(subset_df, path_subset_json)\n",
    "\n",
    "    # split the subset train images into separate dirs by class \n",
    "    split.distribute_files_to_label_dirs(path_model_images)\n",
    "    # Get dataset.json labels for the subset\n",
    "    split.generate_labels_json(path_model_images, path_model_images, \"dataset.json\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    print(f\"Creating dataset for {model_name}...\")\n",
    "    # print('path_home: '+ path_home)\n",
    "    # print('raw_data: '+ path_raw_data)\n",
    "    # print('model_dir: '+ path_model+'/dataset')\n",
    "    # print()\n",
    "    train_model.create_dataset(path_home, path_model_images, path_dataset)\n",
    "\n",
    "    # print()\n",
    "    print(f\"Training {model_name}...\")\n",
    "    train_model.run_stylegan_training(path_home, path_experiments, path_dataset, snap=10)\n",
    "    \n",
    "\n",
    "    # for gen_size in gen_sizes:\n",
    "    #     print(f\"Generating synthetic images for {model_name}...\")\n",
    "    #     train.generate_stylegan_images(path_home, model_dir + '/experiments/.....', model_dir + '/experiments/...' ,gen_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model.generate_stylegan_images('/home/pathorad3090/Documents/Hadar/styleGAN2_replicate', '/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_1.0K_20241103_143534/experiments/00000-dataset-cond-auto1/network-snapshot-000000.pkl','/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_1.0K_20241103_143534/gen' , '1-5')\n",
    "stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def remove_all_files_in_dir(directory):\n",
    "    # Get all files in the directory (excluding subdirectories)\n",
    "    files = glob.glob(os.path.join(directory, '*')) + glob.glob(os.path.join(directory, '.*'))\n",
    "\n",
    "    for file in files:\n",
    "        # if os.path.isfile(file):  # Only delete files, not directories\n",
    "        print(f\"Removing file: {file}\")  # Optional: to show which files are being deleted\n",
    "        os.remove(file)\n",
    "\n",
    "# Usage example\n",
    "dir_path = \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000\"\n",
    "remove_all_files_in_dir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest = path_model + '/dataset'\n",
    "os.path.isdir(dest)\n",
    "os.listdir(dest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results - relevant metric: avg/class accuracy, f1, precision, recall, AUC-ROC...\n",
    "# graph/tabular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete datasets (keep logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image_folder(source_dir, *, max_images=100000):\n",
    "    input_images = [str(f) for f in sorted(Path(source_dir).rglob('*')) if is_image_ext(f) and os.path.isfile(f)]\n",
    "\n",
    "    # Load labels.\n",
    "    labels = {}\n",
    "    meta_fname = os.path.join(source_dir, 'dataset.json')\n",
    "    if os.path.isfile(meta_fname):\n",
    "        with open(meta_fname, 'r') as file:\n",
    "            labels = json.load(file)['labels']\n",
    "            if labels is not None:\n",
    "                labels = { x[0]: x[1] for x in labels }\n",
    "            else:\n",
    "                labels = {}\n",
    "\n",
    "\n",
    "    def iterate_images():\n",
    "        for idx, fname in enumerate(input_images):\n",
    "            arch_fname = os.path.relpath(fname, source_dir)\n",
    "            arch_fname = arch_fname.replace('\\\\', '/')\n",
    "            img = np.array(PIL.Image.open(fname))\n",
    "            yield dict(img=img, label=labels.get(arch_fname))\n",
    "            if idx >= max_idx-1:\n",
    "                break\n",
    "    return max_idx, iterate_images()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
