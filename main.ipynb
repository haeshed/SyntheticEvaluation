{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "# import train_model\n",
    "# import generate_synthetic\n",
    "# import train_classifier\n",
    "# import test_imgs\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import os\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from random import seed\n",
    "\n",
    "\n",
    "import split_dataset as split\n",
    "import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "path_home = '/home/pathorad3090/Documents/Hadar/SyntheticEvaluation'\n",
    "path_models = path_home + \"/models\"\n",
    "path_raw_data = path_home + \"/data/mnist_images\"\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 09:37:09,258 - INFO - Logging setup complete.\n",
      "2024-11-08 09:37:09,259 - INFO - Parameters used: seed=42, train_sizes=[50, 100, 400, 800, 1000, 5000, 10000, 25000, 50000], gen_sizes=[50, 100, 400, 800, 1000, 5000, 10000, 25000, 50000], kimg=500\n",
      "2024-11-08 09:37:09,259 - INFO - log_filename: log_2024_11_08__09_37_09_seed42_trainSizes50_100_400_800_1000_5000_10000_25000_50000_genSizes50_100_400_800_1000_5000_10000_25000_50000_kimg500.log\n",
      "2024-11-08 09:37:09,259 - INFO - Training Configuration:\n",
      "2024-11-08 09:37:09,260 - INFO - Train Sizes: [50, 100, 400, 800, 1000, 5000, 10000, 25000, 50000]\n",
      "2024-11-08 09:37:09,260 - INFO - Generation Sizes: [50, 100, 400, 800, 1000, 5000, 10000, 25000, 50000]\n",
      "2024-11-08 09:37:09,260 - INFO - Train Cutoff: 500\n",
      "2024-11-08 09:37:09,261 - INFO - ----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set parameters for which train_size, gen_size, synthetic/real ratio, GAN train cutoff\n",
    "# Set initial dir for experiments\n",
    "\n",
    "# Set parameters as lists of integer values\n",
    "seed = 42\n",
    "train_sizes = [50, 100, 400, 800, 1000, 5000, 10000, 25000, 50000]  # List of different training sizes\n",
    "gen_sizes = [50, 100, 400, 800, 1000, 5000, 10000, 25000, 50000]  # List of different generation sizes\n",
    "synthetic_real_ratio = 0.5  # Ratio of synthetic to real data\n",
    "gan_train_cutoff = 5000  # Number of GAN training iterations before switching\n",
    "train_ratio = 0.8\n",
    "kimg = 500\n",
    "# Configure logging\n",
    "timestamp = datetime.now().strftime(\"%Y_%m_%d__%H_%M_%S\")\n",
    "log_filename = (f\"log_{timestamp}_seed{seed}_trainSizes{'_'.join(map(str, train_sizes))}_\"\n",
    "                f\"genSizes{'_'.join(map(str, gen_sizes))}_kimg{kimg}.log\")\n",
    "\n",
    "logging.basicConfig(    filename=log_filename, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "# Example log messages\n",
    "logging.info('Logging setup complete.')\n",
    "logging.info('Parameters used: seed=%d, train_sizes=%s, gen_sizes=%s, kimg=%d', seed, train_sizes, gen_sizes, kimg)\n",
    "\n",
    "# Log the configured parameters for verification\n",
    "logger.info('log_filename: '+ log_filename)\n",
    "logger.info(\"Training Configuration:\")\n",
    "logger.info(f\"Train Sizes: {train_sizes}\")\n",
    "logger.info(f\"Generation Sizes: {gen_sizes}\")\n",
    "# logger.info(f\"Synthetic/Real Ratio: {synthetic_real_ratio}\")\n",
    "# logger.info(f\"StyleGAN2-ADA Training Cutoff: {gan_train_cutoff}\")\n",
    "# logger.info(f\"Train Ratio: {train_ratio}\")\n",
    "logger.info(f\"Train Cutoff: {kimg}\")\n",
    "logger.info(\"-\" * 40)  # Separator for clarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use preprocessing.ipynb to create a proper dataset\n",
    "# Distribute files to relevant subfolders + create JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 09:38:22,272 - INFO - Loading data from /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/dataset_full.json for splitting into train/test subsets.\n",
      "2024-11-08 09:38:22,273 - INFO - Splitting data from /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/dataset_full.json with train ratio: 0.8\n",
      "Splitting data: 100%|██████████| 10/10 [00:00<00:00, 100.09class/s]\n",
      "2024-11-08 09:38:22,406 - INFO - Split completed: 47995 training samples and 12005 testing samples.\n",
      "2024-11-08 09:38:22,410 - INFO - Saving training data to /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images/train_data.json.\n",
      "2024-11-08 09:38:22,410 - INFO - Saving data to /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images/train_data.json\n",
      "2024-11-08 09:38:22,474 - INFO - Data saved successfully: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images/train_data.json\n",
      "2024-11-08 09:38:22,476 - INFO - Saving testing data to /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images/test_data.json.\n",
      "2024-11-08 09:38:22,477 - INFO - Saving data to /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images/test_data.json\n",
      "2024-11-08 09:38:22,521 - INFO - Data saved successfully: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images/test_data.json\n",
      "2024-11-08 09:38:22,522 - INFO - Printing class distribution for training and testing datasets.\n",
      "2024-11-08 09:38:22,522 - INFO - Train data statistics:\n",
      "2024-11-08 09:38:22,522 - INFO - Total number of samples: 47995\n",
      "2024-11-08 09:38:22,523 - INFO - Class distribution:\n",
      "0    4738\n",
      "1    5393\n",
      "2    4766\n",
      "3    4904\n",
      "4    4673\n",
      "5    4336\n",
      "6    4734\n",
      "7    5012\n",
      "8    4680\n",
      "9    4759\n",
      "Name: label, dtype: int64\n",
      "2024-11-08 09:38:22,524 - INFO - Test data statistics:\n",
      "2024-11-08 09:38:22,524 - INFO - Total number of samples: 12005\n",
      "2024-11-08 09:38:22,525 - INFO - Class distribution:\n",
      "0    1185\n",
      "1    1349\n",
      "2    1192\n",
      "3    1227\n",
      "4    1169\n",
      "5    1085\n",
      "6    1184\n",
      "7    1253\n",
      "8    1171\n",
      "9    1190\n",
      "Name: label, dtype: int64\n",
      "2024-11-08 09:38:22,525 - INFO - Data splitting and saving completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tick 26    kimg 104.0    time 18m 50s      sec/tick 27.5    sec/kimg 6.88    maintenance 0.0    cpumem 4.61   gpumem 4.63   augment 0.089\n",
      "tick 27    kimg 108.0    time 19m 18s      sec/tick 27.5    sec/kimg 6.88    maintenance 0.0    cpumem 4.61   gpumem 4.63   augment 0.091\n",
      "tick 28    kimg 112.0    time 19m 45s      sec/tick 27.7    sec/kimg 6.94    maintenance 0.0    cpumem 4.61   gpumem 4.63   augment 0.092\n",
      "tick 29    kimg 116.0    time 20m 13s      sec/tick 27.6    sec/kimg 6.89    maintenance 0.0    cpumem 4.61   gpumem 4.63   augment 0.096\n",
      "tick 30    kimg 120.0    time 20m 40s      sec/tick 27.5    sec/kimg 6.87    maintenance 0.0    cpumem 4.61   gpumem 4.63   augment 0.100\n",
      "Evaluating metrics...\n",
      "{\"results\": {\"fid50k_full\": 171.18526304609296}, \"metric\": \"fid50k_full\", \"total_time\": 133.3776662349701, \"total_time_str\": \"2m 13s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000120.pkl\", \"timestamp\": 1731051770.2154694}\n",
      "tick 31    kimg 124.0    time 23m 23s      sec/tick 28.2    sec/kimg 7.04    maintenance 134.6  cpumem 4.61   gpumem 4.63   augment 0.100\n",
      "tick 32    kimg 128.0    time 23m 51s      sec/tick 27.8    sec/kimg 6.94    maintenance 0.0    cpumem 4.61   gpumem 4.63   augment 0.101\n",
      "tick 33    kimg 132.0    time 24m 18s      sec/tick 27.5    sec/kimg 6.86    maintenance 0.0    cpumem 4.61   gpumem 4.63   augment 0.102\n",
      "tick 34    kimg 136.0    time 24m 46s      sec/tick 27.5    sec/kimg 6.87    maintenance 0.0    cpumem 4.61   gpumem 4.63   augment 0.107\n",
      "tick 35    kimg 140.0    time 25m 14s      sec/tick 27.6    sec/kimg 6.89    maintenance 0.0    cpumem 4.61   gpumem 4.63   augment 0.114\n",
      "tick 36    kimg 144.0    time 25m 42s      sec/tick 28.4    sec/kimg 7.11    maintenance 0.0    cpumem 4.61   gpumem 4.63   augment 0.118\n",
      "tick 37    kimg 148.0    time 26m 11s      sec/tick 29.3    sec/kimg 7.32    maintenance 0.0    cpumem 4.61   gpumem 4.63   augment 0.120\n",
      "tick 38    kimg 152.0    time 26m 39s      sec/tick 27.4    sec/kimg 6.86    maintenance 0.0    cpumem 4.61   gpumem 4.63   augment 0.125\n",
      "tick 39    kimg 156.0    time 27m 06s      sec/tick 27.6    sec/kimg 6.89    maintenance 0.0    cpumem 4.61   gpumem 4.63   augment 0.129\n",
      "tick 40    kimg 160.0    time 27m 34s      sec/tick 27.6    sec/kimg 6.90    maintenance 0.0    cpumem 4.61   gpumem 4.63   augment 0.135\n",
      "Evaluating metrics...\n",
      "{\"results\": {\"fid50k_full\": 136.92517422287284}, \"metric\": \"fid50k_full\", \"total_time\": 131.94448137283325, \"total_time_str\": \"2m 12s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000160.pkl\", \"timestamp\": 1731052182.3510742}\n",
      "tick 41    kimg 164.0    time 30m 15s      sec/tick 27.5    sec/kimg 6.87    maintenance 133.2  cpumem 4.61   gpumem 4.63   augment 0.140\n",
      "tick 42    kimg 168.0    time 30m 42s      sec/tick 27.5    sec/kimg 6.87    maintenance 0.0    cpumem 4.61   gpumem 4.63   augment 0.145\n",
      "tick 43    kimg 172.0    time 31m 10s      sec/tick 27.4    sec/kimg 6.86    maintenance 0.0    cpumem 4.61   gpumem 4.63   augment 0.151\n",
      "tick 44    kimg 176.0    time 31m 37s      sec/tick 27.7    sec/kimg 6.92    maintenance 0.0    cpumem 4.61   gpumem 4.63   augment 0.156\n"
     ]
    }
   ],
   "source": [
    "# Define paths and parameters\n",
    "full_json = path_home + '/data/dataset_full.json'\n",
    "train_json = full_json\n",
    "\n",
    "logger.info(f\"Loading data from {full_json} for splitting into train/test subsets.\")\n",
    "\n",
    "# Split into train/test subsets\n",
    "train_df, test_df = split.split_train_test(train_json, train_ratio, seed=seed)\n",
    "\n",
    "train_output_file = f\"{path_raw_data}/train_data.json\"\n",
    "test_output_file = f\"{path_raw_data}/test_data.json\"\n",
    "\n",
    "logger.info(f\"Saving training data to {train_output_file}.\")\n",
    "split.save_json_dataset(train_df, train_output_file)\n",
    "\n",
    "logger.info(f\"Saving testing data to {test_output_file}.\")\n",
    "split.save_json_dataset(test_df, test_output_file)\n",
    "\n",
    "logger.info(\"Printing class distribution for training and testing datasets.\")\n",
    "split.print_class_distribution(train_df, \"Train\")\n",
    "split.print_class_distribution(test_df, \"Test\")\n",
    "\n",
    "logger.info(\"Data splitting and saving completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train MLP/CNN classifier, test for benchmark using test_imgs.py\n",
    "# V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export MKL_SERVICE_FORCE_INTEL=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 09:19:54,432 - INFO - Creating directories for model: model_50_20241108_09-19\n",
      "2024-11-08 09:19:54,433 - INFO - Creating directories for model: model_50_20241108_09-19 in /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19\n",
      "2024-11-08 09:19:54,434 - INFO - Directories created: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19/dataset, /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19/experiments, /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19/images\n",
      "2024-11-08 09:19:54,434 - INFO - Generating subset data from /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images/train_data.json with size 50 and seed 42\n",
      "2024-11-08 09:19:54,434 - INFO - Creating subset from /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images/train_data.json with size: 50\n",
      "Subsetting classes: 100%|██████████| 10/10 [00:00<00:00, 2174.34class/s]\n",
      "2024-11-08 09:19:54,458 - INFO - Subset creation completed with 50 total samples.\n",
      "2024-11-08 09:19:54,459 - INFO - Subset DataFrame created. Path raw data: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images, Path model images: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19/images\n",
      "2024-11-08 09:19:54,459 - INFO - Copying images from /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images to /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19/images\n",
      "2024-11-08 09:19:54,463 - INFO - Saving subset data to /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19/dataset_subset_size_50_seed_42.json\n",
      "2024-11-08 09:19:54,464 - INFO - Saving data to /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19/dataset_subset_size_50_seed_42.json\n",
      "2024-11-08 09:19:54,464 - INFO - Data saved successfully: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19/dataset_subset_size_50_seed_42.json\n",
      "2024-11-08 09:19:54,464 - INFO - Distributing files into label directories at /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19/images\n",
      "2024-11-08 09:19:54,465 - INFO - Distributing files in /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19/images to label directories.\n",
      "2024-11-08 09:19:54,466 - INFO - Generating labels JSON for the subset.\n",
      "2024-11-08 09:19:54,466 - INFO - Starting to generate labels JSON file...\n",
      "2024-11-08 09:19:54,466 - INFO - Base directory: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19/images\n",
      "2024-11-08 09:19:54,467 - INFO - Generated labels JSON file with 50 entries.\n",
      "2024-11-08 09:19:54,467 - INFO - Creating dataset for model_50_20241108_09-19...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset with command: python /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/dataset_tool.py --source /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19/images --dest /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19/dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/dataset_tool.py:205: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  resample = { 'box': PIL.Image.BOX, 'lanczos': PIL.Image.LANCZOS }[resize_filter]\n",
      "/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/dataset_tool.py:205: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  resample = { 'box': PIL.Image.BOX, 'lanczos': PIL.Image.LANCZOS }[resize_filter]\n",
      "100%|██████████| 50/50 [00:00<00:00, 5067.67it/s]\n",
      "2024-11-08 09:19:54,594 - INFO - Training model model_50_20241108_09-19...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: python /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/train.py --snap 10 --cond=1 --outdir /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19/experiments --data /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19/dataset --kimg=500\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 10,\n",
      "  \"network_snapshot_ticks\": 10,\n",
      "  \"metrics\": [\n",
      "    \"fid50k_full\"\n",
      "  ],\n",
      "  \"random_seed\": 0,\n",
      "  \"training_set_kwargs\": {\n",
      "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
      "    \"path\": \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19/dataset\",\n",
      "    \"use_labels\": true,\n",
      "    \"max_size\": 50,\n",
      "    \"xflip\": false,\n",
      "    \"resolution\": 32\n",
      "  },\n",
      "  \"data_loader_kwargs\": {\n",
      "    \"pin_memory\": true,\n",
      "    \"num_workers\": 3,\n",
      "    \"prefetch_factor\": 2\n",
      "  },\n",
      "  \"G_kwargs\": {\n",
      "    \"class_name\": \"training.networks.Generator\",\n",
      "    \"z_dim\": 512,\n",
      "    \"w_dim\": 512,\n",
      "    \"mapping_kwargs\": {\n",
      "      \"num_layers\": 2\n",
      "    },\n",
      "    \"synthesis_kwargs\": {\n",
      "      \"channel_base\": 16384,\n",
      "      \"channel_max\": 512,\n",
      "      \"num_fp16_res\": 4,\n",
      "      \"conv_clamp\": 256\n",
      "    }\n",
      "  },\n",
      "  \"D_kwargs\": {\n",
      "    \"class_name\": \"training.networks.Discriminator\",\n",
      "    \"block_kwargs\": {},\n",
      "    \"mapping_kwargs\": {},\n",
      "    \"epilogue_kwargs\": {\n",
      "      \"mbstd_group_size\": 4\n",
      "    },\n",
      "    \"channel_base\": 16384,\n",
      "    \"channel_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"lr\": 0.0025,\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08\n",
      "  },\n",
      "  \"D_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"lr\": 0.0025,\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08\n",
      "  },\n",
      "  \"loss_kwargs\": {\n",
      "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
      "    \"r1_gamma\": 0.0064\n",
      "  },\n",
      "  \"total_kimg\": 500,\n",
      "  \"batch_size\": 32,\n",
      "  \"batch_gpu\": 32,\n",
      "  \"ema_kimg\": 10.0,\n",
      "  \"ema_rampup\": 0.05,\n",
      "  \"ada_target\": 0.6,\n",
      "  \"augment_kwargs\": {\n",
      "    \"class_name\": \"training.augment.AugmentPipe\",\n",
      "    \"xflip\": 1,\n",
      "    \"rotate90\": 1,\n",
      "    \"xint\": 1,\n",
      "    \"scale\": 1,\n",
      "    \"rotate\": 1,\n",
      "    \"aniso\": 1,\n",
      "    \"xfrac\": 1,\n",
      "    \"brightness\": 1,\n",
      "    \"contrast\": 1,\n",
      "    \"lumaflip\": 1,\n",
      "    \"hue\": 1,\n",
      "    \"saturation\": 1\n",
      "  },\n",
      "  \"run_dir\": \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19/experiments/00000-dataset-cond-auto1-kimg500\"\n",
      "}\n",
      "\n",
      "Output directory:   /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19/experiments/00000-dataset-cond-auto1-kimg500\n",
      "Training data:      /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/run_20241108_09-19/model_50_20241108_09-19/dataset\n",
      "Training duration:  500 kimg\n",
      "Number of GPUs:     1\n",
      "Number of images:   50\n",
      "Image resolution:   32\n",
      "Conditional model:  True\n",
      "Dataset x-flips:    False\n",
      "\n",
      "Creating output directory...\n",
      "Launching processes...\n",
      "Loading training set...\n",
      "\n",
      "Num images:  50\n",
      "Image shape: [3, 32, 32]\n",
      "Label shape: [10]\n",
      "\n",
      "Constructing networks...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_151535/2236560288.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training model {model_name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stylegan_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_home\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_experiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cleaning up model directories for {model_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Hadar/SyntheticEvaluation/train_model.py\u001b[0m in \u001b[0;36mrun_stylegan_training\u001b[0;34m(path_home, path_exp, path_dataset, snap, kimg)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MLH/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MLH/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    954\u001b[0m                 \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MLH/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MLH/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1651\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MLH/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1609\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed!\n",
      "/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/bias_act.py:50: UserWarning: Failed to build CUDA kernels for bias_act. Falling back to slow reference implementation. Details:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1673, in _run_ninja_build\n",
      "    env=env)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/subprocess.py\", line 512, in run\n",
      "    output=stdout, stderr=stderr)\n",
      "subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/bias_act.py\", line 48, in _init\n",
      "    _plugin = custom_ops.get_plugin('bias_act_plugin', sources=sources, extra_cuda_cflags=['--use_fast_math'])\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/custom_ops.py\", line 110, in get_plugin\n",
      "    torch.utils.cpp_extension.load(name=module_name, verbose=verbose_build, sources=sources, **build_kwargs)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1091, in load\n",
      "    keep_intermediates=keep_intermediates)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1302, in _jit_compile\n",
      "    is_standalone=is_standalone)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1407, in _write_ninja_file_and_build_library\n",
      "    error_prefix=f\"Error building extension '{name}'\")\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1683, in _run_ninja_build\n",
      "    raise RuntimeError(message) from e\n",
      "RuntimeError: Error building extension 'bias_act_plugin': [1/2] /usr/bin/nvcc --generate-dependencies-with-compile --dependency-output bias_act.cuda.o.d -DTORCH_EXTENSION_NAME=bias_act_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/TH -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/THC -isystem /home/pathorad3090/miniconda3/envs/MLH/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' --use_fast_math -std=c++14 -c /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/bias_act.cu -o bias_act.cuda.o \n",
      "FAILED: bias_act.cuda.o \n",
      "/usr/bin/nvcc --generate-dependencies-with-compile --dependency-output bias_act.cuda.o.d -DTORCH_EXTENSION_NAME=bias_act_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/TH -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/THC -isystem /home/pathorad3090/miniconda3/envs/MLH/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' --use_fast_math -std=c++14 -c /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/bias_act.cu -o bias_act.cuda.o \n",
      "/usr/include/c++/11/bits/std_function.h:435:145: error: parameter packs not expanded with ‘...’:\n",
      "  435 |         function(_Functor&& __f)\n",
      "      |                                                                                                                                                 ^ \n",
      "/usr/include/c++/11/bits/std_function.h:435:145: note:         ‘_ArgTypes’\n",
      "/usr/include/c++/11/bits/std_function.h:530:146: error: parameter packs not expanded with ‘...’:\n",
      "  530 |         operator=(_Functor&& __f)\n",
      "      |                                                                                                                                                  ^ \n",
      "/usr/include/c++/11/bits/std_function.h:530:146: note:         ‘_ArgTypes’\n",
      "ninja: build stopped: subcommand failed.\n",
      "\n",
      "\n",
      "  warnings.warn('Failed to build CUDA kernels for bias_act. Falling back to slow reference implementation. Details:\\n\\n' + traceback.format_exc())\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Failed!\n",
      "/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/upfirdn2d.py:34: UserWarning: Failed to build CUDA kernels for upfirdn2d. Falling back to slow reference implementation. Details:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1673, in _run_ninja_build\n",
      "    env=env)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/subprocess.py\", line 512, in run\n",
      "    output=stdout, stderr=stderr)\n",
      "subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/upfirdn2d.py\", line 32, in _init\n",
      "    _plugin = custom_ops.get_plugin('upfirdn2d_plugin', sources=sources, extra_cuda_cflags=['--use_fast_math'])\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/custom_ops.py\", line 110, in get_plugin\n",
      "    torch.utils.cpp_extension.load(name=module_name, verbose=verbose_build, sources=sources, **build_kwargs)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1091, in load\n",
      "    keep_intermediates=keep_intermediates)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1302, in _jit_compile\n",
      "    is_standalone=is_standalone)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1407, in _write_ninja_file_and_build_library\n",
      "    error_prefix=f\"Error building extension '{name}'\")\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1683, in _run_ninja_build\n",
      "    raise RuntimeError(message) from e\n",
      "RuntimeError: Error building extension 'upfirdn2d_plugin': [1/2] /usr/bin/nvcc --generate-dependencies-with-compile --dependency-output upfirdn2d.cuda.o.d -DTORCH_EXTENSION_NAME=upfirdn2d_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/TH -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/THC -isystem /home/pathorad3090/miniconda3/envs/MLH/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' --use_fast_math -std=c++14 -c /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/upfirdn2d.cu -o upfirdn2d.cuda.o \n",
      "FAILED: upfirdn2d.cuda.o \n",
      "/usr/bin/nvcc --generate-dependencies-with-compile --dependency-output upfirdn2d.cuda.o.d -DTORCH_EXTENSION_NAME=upfirdn2d_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/TH -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/THC -isystem /home/pathorad3090/miniconda3/envs/MLH/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' --use_fast_math -std=c++14 -c /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/upfirdn2d.cu -o upfirdn2d.cuda.o \n",
      "/usr/include/c++/11/bits/std_function.h:435:145: error: parameter packs not expanded with ‘...’:\n",
      "  435 |         function(_Functor&& __f)\n",
      "      |                                                                                                                                                 ^ \n",
      "/usr/include/c++/11/bits/std_function.h:435:145: note:         ‘_ArgTypes’\n",
      "/usr/include/c++/11/bits/std_function.h:530:146: error: parameter packs not expanded with ‘...’:\n",
      "  530 |         operator=(_Functor&& __f)\n",
      "      |                                                                                                                                                  ^ \n",
      "/usr/include/c++/11/bits/std_function.h:530:146: note:         ‘_ArgTypes’\n",
      "ninja: build stopped: subcommand failed.\n",
      "\n",
      "\n",
      "  warnings.warn('Failed to build CUDA kernels for upfirdn2d. Falling back to slow reference implementation. Details:\\n\\n' + traceback.format_exc())\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "\n",
      "Generator            Parameters  Buffers  Output shape       Datatype\n",
      "---                  ---         ---      ---                ---     \n",
      "mapping.embed        5632        -        [32, 512]          float32 \n",
      "mapping.fc0          524800      -        [32, 512]          float32 \n",
      "mapping.fc1          262656      -        [32, 512]          float32 \n",
      "mapping              -           512      [32, 8, 512]       float32 \n",
      "synthesis.b4.conv1   2622465     32       [32, 512, 4, 4]    float32 \n",
      "synthesis.b4.torgb   264195      -        [32, 3, 4, 4]      float32 \n",
      "synthesis.b4:0       8192        16       [32, 512, 4, 4]    float32 \n",
      "synthesis.b4:1       -           -        [32, 512, 4, 4]    float32 \n",
      "synthesis.b8.conv0   2622465     80       [32, 512, 8, 8]    float16 \n",
      "synthesis.b8.conv1   2622465     80       [32, 512, 8, 8]    float16 \n",
      "synthesis.b8.torgb   264195      -        [32, 3, 8, 8]      float16 \n",
      "synthesis.b8:0       -           16       [32, 512, 8, 8]    float16 \n",
      "synthesis.b8:1       -           -        [32, 512, 8, 8]    float32 \n",
      "synthesis.b16.conv0  2622465     272      [32, 512, 16, 16]  float16 \n",
      "synthesis.b16.conv1  2622465     272      [32, 512, 16, 16]  float16 \n",
      "synthesis.b16.torgb  264195      -        [32, 3, 16, 16]    float16 \n",
      "synthesis.b16:0      -           16       [32, 512, 16, 16]  float16 \n",
      "synthesis.b16:1      -           -        [32, 512, 16, 16]  float32 \n",
      "synthesis.b32.conv0  2622465     1040     [32, 512, 32, 32]  float16 \n",
      "synthesis.b32.conv1  2622465     1040     [32, 512, 32, 32]  float16 \n",
      "synthesis.b32.torgb  264195      -        [32, 3, 32, 32]    float16 \n",
      "synthesis.b32:0      -           16       [32, 512, 32, 32]  float16 \n",
      "synthesis.b32:1      -           -        [32, 512, 32, 32]  float32 \n",
      "---                  ---         ---      ---                ---     \n",
      "Total                20215315    3392     -                  -       \n",
      "\n",
      "\n",
      "Discriminator  Parameters  Buffers  Output shape       Datatype\n",
      "---            ---         ---      ---                ---     \n",
      "b32.fromrgb    2048        16       [32, 512, 32, 32]  float16 \n",
      "b32.skip       262144      16       [32, 512, 16, 16]  float16 \n",
      "b32.conv0      2359808     16       [32, 512, 32, 32]  float16 \n",
      "b32.conv1      2359808     16       [32, 512, 16, 16]  float16 \n",
      "b32            -           16       [32, 512, 16, 16]  float16 \n",
      "b16.skip       262144      16       [32, 512, 8, 8]    float16 \n",
      "b16.conv0      2359808     16       [32, 512, 16, 16]  float16 \n",
      "b16.conv1      2359808     16       [32, 512, 8, 8]    float16 \n",
      "b16            -           16       [32, 512, 8, 8]    float16 \n",
      "b8.skip        262144      16       [32, 512, 4, 4]    float16 \n",
      "b8.conv0       2359808     16       [32, 512, 8, 8]    float16 \n",
      "b8.conv1       2359808     16       [32, 512, 4, 4]    float16 \n",
      "b8             -           16       [32, 512, 4, 4]    float16 \n",
      "mapping.embed  5632        -        [32, 512]          float32 \n",
      "mapping.fc0    262656      -        [32, 512]          float32 \n",
      "mapping.fc1    262656      -        [32, 512]          float32 \n",
      "mapping.fc2    262656      -        [32, 512]          float32 \n",
      "mapping.fc3    262656      -        [32, 512]          float32 \n",
      "mapping.fc4    262656      -        [32, 512]          float32 \n",
      "mapping.fc5    262656      -        [32, 512]          float32 \n",
      "mapping.fc6    262656      -        [32, 512]          float32 \n",
      "mapping.fc7    262656      -        [32, 512]          float32 \n",
      "b4.mbstd       -           -        [32, 513, 4, 4]    float32 \n",
      "b4.conv        2364416     16       [32, 512, 4, 4]    float32 \n",
      "b4.fc          4194816     -        [32, 512]          float32 \n",
      "b4.out         262656      -        [32, 512]          float32 \n",
      "b4             -           -        [32, 1]            float32 \n",
      "---            ---         ---      ---                ---     \n",
      "Total          23876096    224      -                  -       \n",
      "\n",
      "Setting up augmentation...\n",
      "Distributing across 1 GPUs...\n",
      "Setting up training phases...\n",
      "Exporting sample images...\n",
      "Initializing logs...\n",
      "Skipping tfevents export: No module named 'tensorboard'\n",
      "Training for 500 kimg...\n",
      "\n",
      "tick 0     kimg 0.0      time 15s          sec/tick 1.7     sec/kimg 51.60   maintenance 13.0   cpumem 4.25   gpumem 11.70  augment 0.000\n",
      "Evaluating metrics...\n",
      "{\"results\": {\"fid50k_full\": 349.5414651275418}, \"metric\": \"fid50k_full\", \"total_time\": 133.75005912780762, \"total_time_str\": \"2m 14s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1731050544.866795}\n",
      "tick 1     kimg 4.0      time 2m 57s       sec/tick 27.3    sec/kimg 6.81    maintenance 135.0  cpumem 4.60   gpumem 9.29   augment 0.005\n",
      "tick 2     kimg 8.0      time 3m 24s       sec/tick 27.3    sec/kimg 6.82    maintenance 0.0    cpumem 4.60   gpumem 4.63   augment 0.012\n",
      "tick 3     kimg 12.0     time 3m 52s       sec/tick 27.4    sec/kimg 6.85    maintenance 0.0    cpumem 4.60   gpumem 4.63   augment 0.019\n",
      "tick 4     kimg 16.0     time 4m 19s       sec/tick 27.5    sec/kimg 6.87    maintenance 0.0    cpumem 4.60   gpumem 4.63   augment 0.026\n",
      "tick 5     kimg 20.0     time 4m 46s       sec/tick 27.4    sec/kimg 6.84    maintenance 0.0    cpumem 4.60   gpumem 4.63   augment 0.032\n",
      "tick 6     kimg 24.0     time 5m 14s       sec/tick 27.4    sec/kimg 6.84    maintenance 0.0    cpumem 4.60   gpumem 4.63   augment 0.038\n",
      "tick 7     kimg 28.0     time 5m 41s       sec/tick 27.4    sec/kimg 6.86    maintenance 0.0    cpumem 4.60   gpumem 4.63   augment 0.045\n",
      "tick 8     kimg 32.0     time 6m 09s       sec/tick 27.5    sec/kimg 6.88    maintenance 0.0    cpumem 4.60   gpumem 4.63   augment 0.051\n",
      "tick 9     kimg 36.0     time 6m 36s       sec/tick 27.4    sec/kimg 6.84    maintenance 0.0    cpumem 4.60   gpumem 4.63   augment 0.057\n",
      "tick 10    kimg 40.0     time 7m 04s       sec/tick 27.4    sec/kimg 6.86    maintenance 0.0    cpumem 4.60   gpumem 4.63   augment 0.063\n",
      "Evaluating metrics...\n",
      "{\"results\": {\"fid50k_full\": 347.53794780528733}, \"metric\": \"fid50k_full\", \"total_time\": 131.52496933937073, \"total_time_str\": \"2m 12s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000040.pkl\", \"timestamp\": 1731050951.640164}\n",
      "tick 11    kimg 44.0     time 9m 44s       sec/tick 27.2    sec/kimg 6.81    maintenance 132.7  cpumem 4.58   gpumem 4.63   augment 0.067\n",
      "tick 12    kimg 48.0     time 10m 11s      sec/tick 27.4    sec/kimg 6.85    maintenance 0.0    cpumem 4.58   gpumem 4.63   augment 0.074\n",
      "tick 13    kimg 52.0     time 10m 38s      sec/tick 27.4    sec/kimg 6.84    maintenance 0.0    cpumem 4.58   gpumem 4.63   augment 0.077\n",
      "tick 14    kimg 56.0     time 11m 06s      sec/tick 27.4    sec/kimg 6.84    maintenance 0.0    cpumem 4.58   gpumem 4.63   augment 0.081\n",
      "tick 15    kimg 60.0     time 11m 33s      sec/tick 27.4    sec/kimg 6.85    maintenance 0.0    cpumem 4.58   gpumem 4.63   augment 0.085\n",
      "tick 16    kimg 64.0     time 12m 01s      sec/tick 27.5    sec/kimg 6.88    maintenance 0.0    cpumem 4.58   gpumem 4.63   augment 0.085\n",
      "tick 17    kimg 68.0     time 12m 28s      sec/tick 27.5    sec/kimg 6.87    maintenance 0.0    cpumem 4.58   gpumem 4.63   augment 0.088\n",
      "tick 18    kimg 72.0     time 12m 56s      sec/tick 27.5    sec/kimg 6.86    maintenance 0.0    cpumem 4.58   gpumem 4.63   augment 0.090\n",
      "tick 19    kimg 76.0     time 13m 23s      sec/tick 27.6    sec/kimg 6.89    maintenance 0.0    cpumem 4.58   gpumem 4.63   augment 0.090\n",
      "tick 20    kimg 80.0     time 13m 51s      sec/tick 27.6    sec/kimg 6.91    maintenance 0.0    cpumem 4.58   gpumem 4.63   augment 0.091\n",
      "Evaluating metrics...\n",
      "{\"results\": {\"fid50k_full\": 184.89871910489953}, \"metric\": \"fid50k_full\", \"total_time\": 132.448139667511, \"total_time_str\": \"2m 12s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000080.pkl\", \"timestamp\": 1731051359.8843842}\n",
      "tick 21    kimg 84.0     time 16m 32s      sec/tick 27.4    sec/kimg 6.85    maintenance 133.7  cpumem 4.61   gpumem 4.63   augment 0.092\n",
      "tick 22    kimg 88.0     time 17m 00s      sec/tick 27.5    sec/kimg 6.87    maintenance 0.0    cpumem 4.61   gpumem 4.63   augment 0.092\n"
     ]
    }
   ],
   "source": [
    "train_json = path_raw_data + '/train_data.json'\n",
    "path_curr_run = os.path.join(path_models, 'run_' + datetime.now().strftime('%Y%m%d_%H-%M'))\n",
    "# train_sizes = [40000]\n",
    "\n",
    "for train_size in train_sizes:\n",
    "    # Create a name for the subset and the model\n",
    "    model_name = f\"model_{train_size}_{datetime.now().strftime('%Y%m%d_%H-%M')}\"\n",
    "    path_model = os.path.join(path_curr_run, model_name)\n",
    "    path_experiments = os.path.join(path_model, 'experiments')\n",
    "    path_dataset = os.path.join(path_model, 'dataset')\n",
    "    path_subset_json = f\"{path_model}/dataset_subset_size_{train_size}_seed_{seed}.json\"\n",
    "    \n",
    "    logger.info(f\"Creating directories for model: {model_name}\")\n",
    "    _, _, path_model_images = split.open_folders(model_name, path_model)\n",
    "    \n",
    "    logger.info(f\"Generating subset data from {train_json} with size {train_size} and seed {seed}\")\n",
    "    subset_df = split.subset_data(train_json, train_size, seed)\n",
    "    \n",
    "    logger.info(f\"Subset DataFrame created. Path raw data: {path_raw_data}, Path model images: {path_model_images}\")\n",
    "    split.copy_images_to_model_and_dataset(subset_df, path_raw_data, path_model_images)\n",
    "    \n",
    "    logger.info(f\"Saving subset data to {path_subset_json}\")\n",
    "    split.save_json_dataset(subset_df, path_subset_json)\n",
    "\n",
    "    logger.info(f\"Distributing files into label directories at {path_model_images}\")\n",
    "    split.distribute_files_to_label_dirs(path_model_images)\n",
    "    \n",
    "    logger.info(\"Generating labels JSON for the subset.\")\n",
    "    split.generate_labels_json(path_model_images, path_model_images, \"dataset.json\")\n",
    "    \n",
    "    logger.info(f\"Creating dataset for {model_name}...\")\n",
    "    train_model.create_dataset(path_home, path_model_images, path_dataset)\n",
    "\n",
    "    logger.info(f\"Training model {model_name}...\")\n",
    "    train_model.run_stylegan_training(path_home, path_experiments, path_dataset, snap=10, kimg=kimg)\n",
    "    \n",
    "    logger.info(f\"Cleaning up model directories for {model_name}\")\n",
    "    # split.delete_images_and_dataset_dirs(path_model)\n",
    "\n",
    "        \n",
    "        # train the classifier\n",
    "        # split the training step and the gen steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 09:06:19,514 - INFO - Searching for the latest .pkl file in <DirEntry 'model_400_20241105_00-03'>\n",
      "2024-11-08 09:06:19,515 - INFO - Latest .pkl file found: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_400_20241105_00-03/experiments/00000-dataset-cond-auto1-kimg500/network-snapshot-000500.pkl\n",
      "2024-11-08 09:06:19,516 - INFO - Most recent .pkl file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_400_20241105_00-03/experiments/00000-dataset-cond-auto1-kimg500/network-snapshot-000500.pkl\n",
      "2024-11-08 09:06:19,516 - INFO - Generating synthetic images for model_400_20241105_00-03 with generation size 50...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_400_20241105_00-03\n",
      "Running command: python /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/generate.py --outdir=/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_400_20241105_00-03/generations_50/class_0 --seeds=0-5 --class=0 --network=/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_400_20241105_00-03/experiments/00000-dataset-cond-auto1-kimg500/network-snapshot-000500.pkl\n",
      "Loading networks from \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_400_20241105_00-03/experiments/00000-dataset-cond-auto1-kimg500/network-snapshot-000500.pkl\"...\n",
      "Generating image for seed 0 (0/6) ...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Failed!\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/bias_act.py:50: UserWarning: Failed to build CUDA kernels for bias_act. Falling back to slow reference implementation. Details:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1673, in _run_ninja_build\n",
      "    env=env)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/subprocess.py\", line 512, in run\n",
      "    output=stdout, stderr=stderr)\n",
      "subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/bias_act.py\", line 48, in _init\n",
      "    _plugin = custom_ops.get_plugin('bias_act_plugin', sources=sources, extra_cuda_cflags=['--use_fast_math'])\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/custom_ops.py\", line 110, in get_plugin\n",
      "    torch.utils.cpp_extension.load(name=module_name, verbose=verbose_build, sources=sources, **build_kwargs)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1091, in load\n",
      "    keep_intermediates=keep_intermediates)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1302, in _jit_compile\n",
      "    is_standalone=is_standalone)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1407, in _write_ninja_file_and_build_library\n",
      "    error_prefix=f\"Error building extension '{name}'\")\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1683, in _run_ninja_build\n",
      "    raise RuntimeError(message) from e\n",
      "RuntimeError: Error building extension 'bias_act_plugin': [1/2] /usr/bin/nvcc --generate-dependencies-with-compile --dependency-output bias_act.cuda.o.d -DTORCH_EXTENSION_NAME=bias_act_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/TH -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/THC -isystem /home/pathorad3090/miniconda3/envs/MLH/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' --use_fast_math -std=c++14 -c /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/bias_act.cu -o bias_act.cuda.o \n",
      "FAILED: bias_act.cuda.o \n",
      "/usr/bin/nvcc --generate-dependencies-with-compile --dependency-output bias_act.cuda.o.d -DTORCH_EXTENSION_NAME=bias_act_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/TH -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/THC -isystem /home/pathorad3090/miniconda3/envs/MLH/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' --use_fast_math -std=c++14 -c /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/bias_act.cu -o bias_act.cuda.o \n",
      "/usr/include/c++/11/bits/std_function.h:435:145: error: parameter packs not expanded with ‘...’:\n",
      "  435 |         function(_Functor&& __f)\n",
      "      |                                                                                                                                                 ^ \n",
      "/usr/include/c++/11/bits/std_function.h:435:145: note:         ‘_ArgTypes’\n",
      "/usr/include/c++/11/bits/std_function.h:530:146: error: parameter packs not expanded with ‘...’:\n",
      "  530 |         operator=(_Functor&& __f)\n",
      "      |                                                                                                                                                  ^ \n",
      "/usr/include/c++/11/bits/std_function.h:530:146: note:         ‘_ArgTypes’\n",
      "ninja: build stopped: subcommand failed.\n",
      "\n",
      "\n",
      "  warnings.warn('Failed to build CUDA kernels for bias_act. Falling back to slow reference implementation. Details:\\n\\n' + traceback.format_exc())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed!\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "Image shape: (32, 32, 3)\n",
      "Generating image for seed 1 (1/6) ...\n",
      "Image shape: (32, 32, 3)\n",
      "Generating image for seed 2 (2/6) ...\n",
      "Image shape: (32, 32, 3)\n",
      "Generating image for seed 3 (3/6) ...\n",
      "Image shape: (32, 32, 3)\n",
      "Generating image for seed 4 (4/6) ...\n",
      "Image shape: (32, 32, 3)\n",
      "Generating image for seed 5 (5/6) ...\n",
      "Image shape: (32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/upfirdn2d.py:34: UserWarning: Failed to build CUDA kernels for upfirdn2d. Falling back to slow reference implementation. Details:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1673, in _run_ninja_build\n",
      "    env=env)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/subprocess.py\", line 512, in run\n",
      "    output=stdout, stderr=stderr)\n",
      "subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/upfirdn2d.py\", line 32, in _init\n",
      "    _plugin = custom_ops.get_plugin('upfirdn2d_plugin', sources=sources, extra_cuda_cflags=['--use_fast_math'])\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/custom_ops.py\", line 110, in get_plugin\n",
      "    torch.utils.cpp_extension.load(name=module_name, verbose=verbose_build, sources=sources, **build_kwargs)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1091, in load\n",
      "    keep_intermediates=keep_intermediates)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1302, in _jit_compile\n",
      "    is_standalone=is_standalone)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1407, in _write_ninja_file_and_build_library\n",
      "    error_prefix=f\"Error building extension '{name}'\")\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1683, in _run_ninja_build\n",
      "    raise RuntimeError(message) from e\n",
      "RuntimeError: Error building extension 'upfirdn2d_plugin': [1/2] /usr/bin/nvcc --generate-dependencies-with-compile --dependency-output upfirdn2d.cuda.o.d -DTORCH_EXTENSION_NAME=upfirdn2d_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/TH -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/THC -isystem /home/pathorad3090/miniconda3/envs/MLH/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' --use_fast_math -std=c++14 -c /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/upfirdn2d.cu -o upfirdn2d.cuda.o \n",
      "FAILED: upfirdn2d.cuda.o \n",
      "/usr/bin/nvcc --generate-dependencies-with-compile --dependency-output upfirdn2d.cuda.o.d -DTORCH_EXTENSION_NAME=upfirdn2d_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/TH -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/THC -isystem /home/pathorad3090/miniconda3/envs/MLH/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' --use_fast_math -std=c++14 -c /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/upfirdn2d.cu -o upfirdn2d.cuda.o \n",
      "/usr/include/c++/11/bits/std_function.h:435:145: error: parameter packs not expanded with ‘...’:\n",
      "  435 |         function(_Functor&& __f)\n",
      "      |                                                                                                                                                 ^ \n",
      "/usr/include/c++/11/bits/std_function.h:435:145: note:         ‘_ArgTypes’\n",
      "/usr/include/c++/11/bits/std_function.h:530:146: error: parameter packs not expanded with ‘...’:\n",
      "  530 |         operator=(_Functor&& __f)\n",
      "      |                                                                                                                                                  ^ \n",
      "/usr/include/c++/11/bits/std_function.h:530:146: note:         ‘_ArgTypes’\n",
      "ninja: build stopped: subcommand failed.\n",
      "\n",
      "\n",
      "  warnings.warn('Failed to build CUDA kernels for upfirdn2d. Falling back to slow reference implementation. Details:\\n\\n' + traceback.format_exc())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images for class 0 generated successfully in /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_400_20241105_00-03/generations_50/class_0\n",
      "Running command: python /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/generate.py --outdir=/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_400_20241105_00-03/generations_50/class_1 --seeds=0-5 --class=1 --network=/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_400_20241105_00-03/experiments/00000-dataset-cond-auto1-kimg500/network-snapshot-000500.pkl\n",
      "Loading networks from \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_400_20241105_00-03/experiments/00000-dataset-cond-auto1-kimg500/network-snapshot-000500.pkl\"...\n",
      "Generating image for seed 0 (0/6) ...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_84339/2267175675.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mpath_generations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'generations_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Generating synthetic images for {entry.name} with generation size {gen_size * 10}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mtrain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_stylegan_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_home\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_latest_pkl_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_generations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"0-{gen_size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No .pkl file found for generation.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Hadar/SyntheticEvaluation/train_model.py\u001b[0m in \u001b[0;36mgenerate_stylegan_images\u001b[0;34m(path_home, path_model, path_out, seeds_num)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Images for class {class_num} generated successfully in {class_out_dir}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MLH/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MLH/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    954\u001b[0m                 \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MLH/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MLH/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1651\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/MLH/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1609\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed!\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/bias_act.py:50: UserWarning: Failed to build CUDA kernels for bias_act. Falling back to slow reference implementation. Details:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1673, in _run_ninja_build\n",
      "    env=env)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/subprocess.py\", line 512, in run\n",
      "    output=stdout, stderr=stderr)\n",
      "subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/bias_act.py\", line 48, in _init\n",
      "    _plugin = custom_ops.get_plugin('bias_act_plugin', sources=sources, extra_cuda_cflags=['--use_fast_math'])\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/custom_ops.py\", line 110, in get_plugin\n",
      "    torch.utils.cpp_extension.load(name=module_name, verbose=verbose_build, sources=sources, **build_kwargs)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1091, in load\n",
      "    keep_intermediates=keep_intermediates)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1302, in _jit_compile\n",
      "    is_standalone=is_standalone)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1407, in _write_ninja_file_and_build_library\n",
      "    error_prefix=f\"Error building extension '{name}'\")\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1683, in _run_ninja_build\n",
      "    raise RuntimeError(message) from e\n",
      "RuntimeError: Error building extension 'bias_act_plugin': [1/2] /usr/bin/nvcc --generate-dependencies-with-compile --dependency-output bias_act.cuda.o.d -DTORCH_EXTENSION_NAME=bias_act_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/TH -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/THC -isystem /home/pathorad3090/miniconda3/envs/MLH/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' --use_fast_math -std=c++14 -c /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/bias_act.cu -o bias_act.cuda.o \n",
      "FAILED: bias_act.cuda.o \n",
      "/usr/bin/nvcc --generate-dependencies-with-compile --dependency-output bias_act.cuda.o.d -DTORCH_EXTENSION_NAME=bias_act_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/TH -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/THC -isystem /home/pathorad3090/miniconda3/envs/MLH/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' --use_fast_math -std=c++14 -c /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/bias_act.cu -o bias_act.cuda.o \n",
      "/usr/include/c++/11/bits/std_function.h:435:145: error: parameter packs not expanded with ‘...’:\n",
      "  435 |         function(_Functor&& __f)\n",
      "      |                                                                                                                                                 ^ \n",
      "/usr/include/c++/11/bits/std_function.h:435:145: note:         ‘_ArgTypes’\n",
      "/usr/include/c++/11/bits/std_function.h:530:146: error: parameter packs not expanded with ‘...’:\n",
      "  530 |         operator=(_Functor&& __f)\n",
      "      |                                                                                                                                                  ^ \n",
      "/usr/include/c++/11/bits/std_function.h:530:146: note:         ‘_ArgTypes’\n",
      "ninja: build stopped: subcommand failed.\n",
      "\n",
      "\n",
      "  warnings.warn('Failed to build CUDA kernels for bias_act. Falling back to slow reference implementation. Details:\\n\\n' + traceback.format_exc())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed!\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "Image shape: (32, 32, 3)\n",
      "Generating image for seed 1 (1/6) ...\n",
      "Image shape: (32, 32, 3)\n",
      "Generating image for seed 2 (2/6) ...\n",
      "Image shape: (32, 32, 3)\n",
      "Generating image for seed 3 (3/6) ...\n",
      "Image shape: (32, 32, 3)\n",
      "Generating image for seed 4 (4/6) ...\n",
      "Image shape: (32, 32, 3)\n",
      "Generating image for seed 5 (5/6) ...\n",
      "Image shape: (32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/upfirdn2d.py:34: UserWarning: Failed to build CUDA kernels for upfirdn2d. Falling back to slow reference implementation. Details:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1673, in _run_ninja_build\n",
      "    env=env)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/subprocess.py\", line 512, in run\n",
      "    output=stdout, stderr=stderr)\n",
      "subprocess.CalledProcessError: Command '['ninja', '-v']' returned non-zero exit status 1.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/upfirdn2d.py\", line 32, in _init\n",
      "    _plugin = custom_ops.get_plugin('upfirdn2d_plugin', sources=sources, extra_cuda_cflags=['--use_fast_math'])\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/custom_ops.py\", line 110, in get_plugin\n",
      "    torch.utils.cpp_extension.load(name=module_name, verbose=verbose_build, sources=sources, **build_kwargs)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1091, in load\n",
      "    keep_intermediates=keep_intermediates)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1302, in _jit_compile\n",
      "    is_standalone=is_standalone)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1407, in _write_ninja_file_and_build_library\n",
      "    error_prefix=f\"Error building extension '{name}'\")\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/cpp_extension.py\", line 1683, in _run_ninja_build\n",
      "    raise RuntimeError(message) from e\n",
      "RuntimeError: Error building extension 'upfirdn2d_plugin': [1/2] /usr/bin/nvcc --generate-dependencies-with-compile --dependency-output upfirdn2d.cuda.o.d -DTORCH_EXTENSION_NAME=upfirdn2d_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/TH -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/THC -isystem /home/pathorad3090/miniconda3/envs/MLH/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' --use_fast_math -std=c++14 -c /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/upfirdn2d.cu -o upfirdn2d.cuda.o \n",
      "FAILED: upfirdn2d.cuda.o \n",
      "/usr/bin/nvcc --generate-dependencies-with-compile --dependency-output upfirdn2d.cuda.o.d -DTORCH_EXTENSION_NAME=upfirdn2d_plugin -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/TH -isystem /home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/include/THC -isystem /home/pathorad3090/miniconda3/envs/MLH/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' --use_fast_math -std=c++14 -c /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/torch_utils/ops/upfirdn2d.cu -o upfirdn2d.cuda.o \n",
      "/usr/include/c++/11/bits/std_function.h:435:145: error: parameter packs not expanded with ‘...’:\n",
      "  435 |         function(_Functor&& __f)\n",
      "      |                                                                                                                                                 ^ \n",
      "/usr/include/c++/11/bits/std_function.h:435:145: note:         ‘_ArgTypes’\n",
      "/usr/include/c++/11/bits/std_function.h:530:146: error: parameter packs not expanded with ‘...’:\n",
      "  530 |         operator=(_Functor&& __f)\n",
      "      |                                                                                                                                                  ^ \n",
      "/usr/include/c++/11/bits/std_function.h:530:146: note:         ‘_ArgTypes’\n",
      "ninja: build stopped: subcommand failed.\n",
      "\n",
      "\n",
      "  warnings.warn('Failed to build CUDA kernels for upfirdn2d. Falling back to slow reference implementation. Details:\\n\\n' + traceback.format_exc())\n"
     ]
    }
   ],
   "source": [
    "path_curr_run = os.path.join(path_models, 'run_' + datetime.now().strftime('%Y%m%d_%H-%M'))\n",
    "path_curr_run = '/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models'\n",
    "\n",
    "for entry in os.scandir(path_curr_run):\n",
    "    if entry.is_dir() and 'model' in str(entry.name):\n",
    "        print(entry.name)\n",
    "        path_model = entry\n",
    "        path_latest_pkl_file = split.get_latest_pkl_file(path_model)\n",
    "        if path_latest_pkl_file:\n",
    "            logger.info(f\"Most recent .pkl file: {path_latest_pkl_file}\")\n",
    "            for gen_size in gen_sizes:\n",
    "                gen_size = gen_size // 10\n",
    "                path_generations = os.path.join(path_model, 'generations_'+ str(gen_size * 10))\n",
    "                logger.info(f\"Generating synthetic images for {entry.name} with generation size {gen_size * 10}...\")\n",
    "                train_model.generate_stylegan_images(path_home, path_latest_pkl_file, path_generations, f\"0-{gen_size}\")\n",
    "        else:\n",
    "            logger.warning(\"No .pkl file found for generation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_400_20241105_00-03\n",
      "model_1000_20241105_03-06\n",
      "model_50_20241104_21-01\n",
      "model_5000_20241105_04-38\n",
      "model_100_20241104_22-32\n",
      "model_800_20241105_01-35\n",
      "model_10000_20241105_06-09\n"
     ]
    }
   ],
   "source": [
    "path_curr_run = os.path.join(path_models, 'run_' + datetime.now().strftime('%Y%m%d_%H-%M'))\n",
    "path_curr_run = '/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models'\n",
    "\n",
    "for entry in os.scandir(path_curr_run):\n",
    "    if entry.is_dir() and 'model' in str(entry.name):\n",
    "        print(entry.name)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results - relevant metric: avg/class accuracy, f1, precision, recall, AUC-ROC...\n",
    "# graph/tabular\n",
    "logging.shutdown()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
