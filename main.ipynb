{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import .py files\n",
    "import os\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import json\n",
    "# import train_model\n",
    "# import generate_synthetic\n",
    "# import train_classifier\n",
    "# import test_imgs\n",
    "import split_dataset as split\n",
    "import train_model\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_home = '/home/pathorad3090/Documents/Hadar/SyntheticEvaluation'\n",
    "path_models = path_home + \"/models\"\n",
    "path_raw_data = path_home + \"/data/mnist_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "Train Size: [1000, 2000, 3000]\n",
      "Generation Size: [500, 1000, 1500]\n",
      "Synthetic/Real Ratio: 0.5\n",
      "StyleGAN2-ADA Training Cutoff: 5000\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# set parameters for which train_size, gen_size, synthetic/real ratio, GAN train cutoff\n",
    "# set initial dir for experiments\n",
    "\n",
    "# Set parameters as lists of integer values\n",
    "seed = 42\n",
    "train_sizes = [1000, 2000, 3000]  # List of different training sizes\n",
    "gen_sizes = [500, 1000, 1500]      # List of different generation sizes\n",
    "synthetic_real_ratio = 0.5          # Ratio of synthetic to real data\n",
    "gan_train_cutoff = 5000             # Number of GAN training iterations before switching\n",
    "train_ratio = 0.8\n",
    "\n",
    "\n",
    "# Print out the configured parameters for verification\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"Train Size: {train_sizes}\")\n",
    "print(f\"Generation Size: {gen_sizes}\")\n",
    "print(f\"Synthetic/Real Ratio: {synthetic_real_ratio}\")\n",
    "print(f\"StyleGAN2-ADA Training Cutoff: {gan_train_cutoff}\")\n",
    "# print(f\"Experiment Run Directory: {experiment_run_dir}\")\n",
    "print(\"-\" * 40)  # Separator for clarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use preprocessing.ipynb to create a proper dataset\n",
    "# Distribute files to relevant subfolders + create JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting data: 100%|██████████| 10/10 [00:00<00:00, 112.27class/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data statistics:\n",
      "Total number of samples: 47995\n",
      "0    4738\n",
      "1    5393\n",
      "2    4766\n",
      "3    4904\n",
      "4    4673\n",
      "5    4336\n",
      "6    4734\n",
      "7    5012\n",
      "8    4680\n",
      "9    4759\n",
      "Name: label, dtype: int64\n",
      "Test data statistics:\n",
      "Total number of samples: 12005\n",
      "0    1185\n",
      "1    1349\n",
      "2    1192\n",
      "3    1227\n",
      "4    1169\n",
      "5    1085\n",
      "6    1184\n",
      "7    1253\n",
      "8    1171\n",
      "9    1190\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# split into train/test\n",
    "\n",
    "full_json = path_home + '/data/dataset_full.json'\n",
    "\n",
    "# split into test/train subsets\n",
    "train_json = full_json\n",
    "\n",
    "train_df, test_df = split.split_train_test(train_json, train_ratio, seed=seed)\n",
    "\n",
    "train_output_file = f\"{path_raw_data}/train_data.json\"\n",
    "test_output_file = f\"{path_raw_data}/test_data.json\"\n",
    "\n",
    "split.save_data(train_df, train_output_file)\n",
    "split.save_data(test_df, test_output_file)\n",
    "\n",
    "split.print_class_distribution(train_df, \"Train\")\n",
    "split.print_class_distribution(test_df, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train MLP/CNN classifier, test for benchmark using test_imgs.py\n",
    "# V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export MKL_SERVICE_FORCE_INTEL=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subsetting classes: 100%|██████████| 10/10 [00:00<00:00, 2282.86class/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset_df, path_raw_data, path_model_images:  /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/images\n",
      "Starting to generate labels JSON file...\n",
      "Base directory: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/images\n",
      "Generated labels JSON file with 50 entries.\n",
      "Creating dataset for model_0.0K...\n",
      "Creating dataset with command: python /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/dataset_tool.py --source /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/images --dest /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset\n",
      "Error: --dest folder must be empty\n",
      "Error while running the command: Command 'python /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/dataset_tool.py --source /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/images --dest /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset' returned non-zero exit status 1.\n",
      "Running command: python /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/train.py --snap 10 --cond=1 --outdir /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/experiments --data /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  /opt/conda/conda-bld/pytorch_1616554800319/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
      "\n",
      "Training options:\n",
      "{\n",
      "  \"num_gpus\": 1,\n",
      "  \"image_snapshot_ticks\": 10,\n",
      "  \"network_snapshot_ticks\": 10,\n",
      "  \"metrics\": [\n",
      "    \"fid50k_full\"\n",
      "  ],\n",
      "  \"random_seed\": 0,\n",
      "  \"training_set_kwargs\": {\n",
      "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
      "    \"path\": \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset\",\n",
      "    \"use_labels\": true,\n",
      "    \"max_size\": 50,\n",
      "    \"xflip\": false,\n",
      "    \"resolution\": 32\n",
      "  },\n",
      "  \"data_loader_kwargs\": {\n",
      "    \"pin_memory\": true,\n",
      "    \"num_workers\": 3,\n",
      "    \"prefetch_factor\": 2\n",
      "  },\n",
      "  \"G_kwargs\": {\n",
      "    \"class_name\": \"training.networks.Generator\",\n",
      "    \"z_dim\": 512,\n",
      "    \"w_dim\": 512,\n",
      "    \"mapping_kwargs\": {\n",
      "      \"num_layers\": 2\n",
      "    },\n",
      "    \"synthesis_kwargs\": {\n",
      "      \"channel_base\": 16384,\n",
      "      \"channel_max\": 512,\n",
      "      \"num_fp16_res\": 4,\n",
      "      \"conv_clamp\": 256\n",
      "    }\n",
      "  },\n",
      "  \"D_kwargs\": {\n",
      "    \"class_name\": \"training.networks.Discriminator\",\n",
      "    \"block_kwargs\": {},\n",
      "    \"mapping_kwargs\": {},\n",
      "    \"epilogue_kwargs\": {\n",
      "      \"mbstd_group_size\": 4\n",
      "    },\n",
      "    \"channel_base\": 16384,\n",
      "    \"channel_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"lr\": 0.0025,\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08\n",
      "  },\n",
      "  \"D_opt_kwargs\": {\n",
      "    \"class_name\": \"torch.optim.Adam\",\n",
      "    \"lr\": 0.0025,\n",
      "    \"betas\": [\n",
      "      0,\n",
      "      0.99\n",
      "    ],\n",
      "    \"eps\": 1e-08\n",
      "  },\n",
      "  \"loss_kwargs\": {\n",
      "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
      "    \"r1_gamma\": 0.0064\n",
      "  },\n",
      "  \"total_kimg\": 25000,\n",
      "  \"batch_size\": 32,\n",
      "  \"batch_gpu\": 32,\n",
      "  \"ema_kimg\": 10.0,\n",
      "  \"ema_rampup\": 0.05,\n",
      "  \"ada_target\": 0.6,\n",
      "  \"augment_kwargs\": {\n",
      "    \"class_name\": \"training.augment.AugmentPipe\",\n",
      "    \"xflip\": 1,\n",
      "    \"rotate90\": 1,\n",
      "    \"xint\": 1,\n",
      "    \"scale\": 1,\n",
      "    \"rotate\": 1,\n",
      "    \"aniso\": 1,\n",
      "    \"xfrac\": 1,\n",
      "    \"brightness\": 1,\n",
      "    \"contrast\": 1,\n",
      "    \"lumaflip\": 1,\n",
      "    \"hue\": 1,\n",
      "    \"saturation\": 1\n",
      "  },\n",
      "  \"run_dir\": \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/experiments/00000-dataset-cond-auto1\"\n",
      "}\n",
      "\n",
      "Output directory:   /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/experiments/00000-dataset-cond-auto1\n",
      "Training data:      /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset\n",
      "Training duration:  25000 kimg\n",
      "Number of GPUs:     1\n",
      "Number of images:   50\n",
      "Image resolution:   32\n",
      "Conditional model:  True\n",
      "Dataset x-flips:    False\n",
      "\n",
      "Creating output directory...\n",
      "Launching processes...\n",
      "Loading training set...\n",
      "\n",
      "Num images:  50\n",
      "Image shape: [3, 32, 32]\n",
      "Label shape: [10]\n",
      "\n",
      "Constructing networks...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/train.py\", line 537, in <module>\n",
      "    main() # pylint: disable=no-value-for-parameter\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/click/core.py\", line 1128, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/click/core.py\", line 1053, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/click/core.py\", line 1395, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/click/core.py\", line 754, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/click/decorators.py\", line 26, in new_func\n",
      "    return f(get_current_context(), *args, **kwargs)\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/train.py\", line 530, in main\n",
      "    subprocess_fn(rank=0, args=args, temp_dir=temp_dir)\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/train.py\", line 382, in subprocess_fn\n",
      "    training_loop.training_loop(rank=rank, **args)\n",
      "  File \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/training/training_loop.py\", line 150, in training_loop\n",
      "    G = dnnlib.util.construct_class_by_name(**G_kwargs, **common_kwargs).train().requires_grad_(False).to(device) # subclass of torch.nn.Module\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 673, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 387, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 387, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 387, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 1 more time]\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 409, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 671, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/cuda/__init__.py\", line 170, in _lazy_init\n",
      "    torch._C._cuda_init()\n",
      "RuntimeError: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW\n",
      "Error in atexit._run_exitfuncs:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "  File \"/home/pathorad3090/miniconda3/envs/MLH/lib/python3.7/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 3711499) is killed by signal: Terminated. \n",
      "Error while running the command: Command 'python /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/stylegan2-ada-pytorch/train.py --snap 10 --cond=1 --outdir /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/experiments --data /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "# for loop: create dir, create dataset, train model, generate syn-images, test\n",
    "\n",
    "# from random import seed\n",
    "train_json = path_raw_data + '/train_data.json'\n",
    "# input_file = path_home + '/data/dataset.json'\n",
    "\n",
    "\n",
    "\n",
    "# train_sizes = [1000]\n",
    "train_sizes = [5]\n",
    "for train_size in train_sizes:\n",
    "    # Create a name for the subset and the model\n",
    "    model_name = f\"model_{float(train_size) // 1000}K\"\n",
    "    path_model = os.path.join(path_models, model_name)\n",
    "    path_experiments = os.path.join(path_model, 'experiments')\n",
    "    path_dataset = os.path.join(path_model, 'dataset')\n",
    "    _,_,path_model_images = split.open_folders(model_name, path_model)\n",
    "    \n",
    "    subset_df = split.subset_data(train_json, train_size, seed)\n",
    "    # print('subset_df: ',subset_df)\n",
    "    print('subset_df, path_raw_data, path_model_images: ', path_raw_data, path_model_images)\n",
    "    split.copy_images_to_model_and_dataset(subset_df, path_raw_data, path_model_images)\n",
    "    path_subset_json = f\"{path_model}/dataset_subset_size_{train_size}_seed_{seed}.json\"\n",
    "    split.save_data(subset_df, path_subset_json)\n",
    "\n",
    "\n",
    "    split.distribute_files_to_label_dirs(path_model_images)\n",
    "\n",
    "    split.generate_labels_json(path_model_images, path_model_images, \"dataset.json\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    print(f\"Creating dataset for {model_name}...\")\n",
    "    # print('path_home: '+ path_home)\n",
    "    # print('raw_data: '+ path_raw_data)\n",
    "    # print('model_dir: '+ path_model+'/dataset')\n",
    "    # print()\n",
    "    train_model.create_dataset(path_home, path_model_images, path_dataset)\n",
    "\n",
    "    # print()\n",
    "    # print(f\"Training {model_name}...\")\n",
    "    train_model.run_stylegan_training(path_home, path_experiments, path_dataset, snap=10)\n",
    "    \n",
    "\n",
    "    # for gen_size in gen_sizes:\n",
    "    #     print(f\"Generating synthetic images for {model_name}...\")\n",
    "    #     train.generate_stylegan_images(path_home, model_dir + '/experiments/.....', model_dir + '/experiments/...' ,gen_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000022.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000031.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000011.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000041.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000044.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000006.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000016.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000020.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000032.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000047.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000029.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000003.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000021.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000035.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000023.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000024.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000036.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000049.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000001.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000014.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000040.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000045.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000007.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000025.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000010.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000034.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000039.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000028.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000005.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000009.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000008.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000017.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000004.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000046.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000002.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000037.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000030.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000013.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000018.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000026.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000033.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000048.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000038.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000015.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000027.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000042.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000043.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000019.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000000.png\n",
      "Removing file: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000/img00000012.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def remove_all_files_in_dir(directory):\n",
    "    # Get all files in the directory (excluding subdirectories)\n",
    "    files = glob.glob(os.path.join(directory, '*')) + glob.glob(os.path.join(directory, '.*'))\n",
    "\n",
    "    for file in files:\n",
    "        # if os.path.isfile(file):  # Only delete files, not directories\n",
    "        print(f\"Removing file: {file}\")  # Optional: to show which files are being deleted\n",
    "        os.remove(file)\n",
    "\n",
    "# Usage example\n",
    "dir_path = \"/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models/model_0.0K/dataset/00000\"\n",
    "remove_all_files_in_dir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00000', 'dataset.json']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest = path_model + '/dataset'\n",
    "os.path.isdir(dest)\n",
    "os.listdir(dest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results - relevant metric: avg/class accuracy, f1, precision, recall, AUC-ROC...\n",
    "# graph/tabular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete datasets (keep logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image_folder(source_dir, *, max_images=100000):\n",
    "    input_images = [str(f) for f in sorted(Path(source_dir).rglob('*')) if is_image_ext(f) and os.path.isfile(f)]\n",
    "\n",
    "    # Load labels.\n",
    "    labels = {}\n",
    "    meta_fname = os.path.join(source_dir, 'dataset.json')\n",
    "    if os.path.isfile(meta_fname):\n",
    "        with open(meta_fname, 'r') as file:\n",
    "            labels = json.load(file)['labels']\n",
    "            if labels is not None:\n",
    "                labels = { x[0]: x[1] for x in labels }\n",
    "            else:\n",
    "                labels = {}\n",
    "\n",
    "\n",
    "    def iterate_images():\n",
    "        for idx, fname in enumerate(input_images):\n",
    "            arch_fname = os.path.relpath(fname, source_dir)\n",
    "            arch_fname = arch_fname.replace('\\\\', '/')\n",
    "            img = np.array(PIL.Image.open(fname))\n",
    "            yield dict(img=img, label=labels.get(arch_fname))\n",
    "            if idx >= max_idx-1:\n",
    "                break\n",
    "    return max_idx, iterate_images()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
