{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "# import train_model\n",
    "# import generate_synthetic\n",
    "# import train_classifier\n",
    "# import test_imgs\n",
    "import numpy as np\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import os\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from random import seed\n",
    "\n",
    "\n",
    "import split_dataset as split\n",
    "import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path_home = '/home/pathorad3090/Documents/Hadar/SyntheticEvaluation'\n",
    "path_models = path_home + \"/models\"\n",
    "path_raw_data = path_home + \"/data/mnist_images\"\n",
    "path_cnn_classifier = path_home + '/cnn_classifier'\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set parameters for which train_size, gen_size, synthetic/real ratio, GAN train cutoff\n",
    "# Set initial dir for experiments\n",
    "\n",
    "# Set parameters as lists of integer values\n",
    "seed = 42\n",
    "train_sizes = [50, 100, 400, 800, 1000, 5000, 10000, 25000, 50000]  # List of different training sizes\n",
    "gen_sizes = [50, 100, 400, 800, 1000, 5000, 10000, 25000, 50000]  # List of different generation sizes\n",
    "synthetic_real_ratio = 0.5  # Ratio of synthetic to real data\n",
    "gan_train_cutoff = 5000  # Number of GAN training iterations before switching\n",
    "train_ratio = 0.8\n",
    "kimg = 500\n",
    "# Configure logging\n",
    "timestamp = datetime.now().strftime(\"%Y_%m_%d__%H_%M_%S\")\n",
    "log_filename = (f\"log_{timestamp}_seed{seed}_trainSizes{'_'.join(map(str, train_sizes))}_\"\n",
    "                f\"genSizes{'_'.join(map(str, gen_sizes))}_kimg{kimg}.log\")\n",
    "\n",
    "logging.basicConfig(    filename=log_filename, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "# Example log messages\n",
    "logging.info('Logging setup complete.')\n",
    "logging.info('Parameters used: seed=%d, train_sizes=%s, gen_sizes=%s, kimg=%d', seed, train_sizes, gen_sizes, kimg)\n",
    "\n",
    "# Log the configured parameters for verification\n",
    "logger.info('log_filename: '+ log_filename)\n",
    "logger.info(\"Training Configuration:\")\n",
    "logger.info(f\"Train Sizes: {train_sizes}\")\n",
    "logger.info(f\"Generation Sizes: {gen_sizes}\")\n",
    "# logger.info(f\"Synthetic/Real Ratio: {synthetic_real_ratio}\")\n",
    "# logger.info(f\"StyleGAN2-ADA Training Cutoff: {gan_train_cutoff}\")\n",
    "# logger.info(f\"Train Ratio: {train_ratio}\")\n",
    "logger.info(f\"Train Cutoff: {kimg}\")\n",
    "logger.info(\"-\" * 40)  # Separator for clarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use preprocessing.ipynb to create a proper dataset\n",
    "# Distribute files to relevant subfolders + create JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 11:40:41,210 - INFO - Loading data from /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/dataset_full.json for splitting into train/test subsets.\n",
      "2024-11-08 11:40:41,211 - INFO - Splitting data from /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/dataset_full.json with train ratio: 0.8\n",
      "Splitting data: 100%|██████████| 10/10 [00:00<00:00, 104.74class/s]\n",
      "2024-11-08 11:40:41,342 - INFO - Split completed: 47995 training samples and 12005 testing samples.\n",
      "2024-11-08 11:40:41,346 - INFO - Saving training data to /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images/train_data.json.\n",
      "2024-11-08 11:40:41,347 - INFO - Saving data to /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images/train_data.json\n",
      "2024-11-08 11:40:41,421 - INFO - Data saved successfully: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images/train_data.json\n",
      "2024-11-08 11:40:41,423 - INFO - Saving testing data to /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images/test_data.json.\n",
      "2024-11-08 11:40:41,424 - INFO - Saving data to /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images/test_data.json\n",
      "2024-11-08 11:40:41,466 - INFO - Data saved successfully: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images/test_data.json\n",
      "2024-11-08 11:40:41,467 - INFO - Printing class distribution for training and testing datasets.\n",
      "2024-11-08 11:40:41,467 - INFO - Train data statistics:\n",
      "2024-11-08 11:40:41,468 - INFO - Total number of samples: 47995\n",
      "2024-11-08 11:40:41,469 - INFO - Class distribution:\n",
      "0    4738\n",
      "1    5393\n",
      "2    4766\n",
      "3    4904\n",
      "4    4673\n",
      "5    4336\n",
      "6    4734\n",
      "7    5012\n",
      "8    4680\n",
      "9    4759\n",
      "Name: label, dtype: int64\n",
      "2024-11-08 11:40:41,469 - INFO - Test data statistics:\n",
      "2024-11-08 11:40:41,469 - INFO - Total number of samples: 12005\n",
      "2024-11-08 11:40:41,470 - INFO - Class distribution:\n",
      "0    1185\n",
      "1    1349\n",
      "2    1192\n",
      "3    1227\n",
      "4    1169\n",
      "5    1085\n",
      "6    1184\n",
      "7    1253\n",
      "8    1171\n",
      "9    1190\n",
      "Name: label, dtype: int64\n",
      "2024-11-08 11:40:41,471 - INFO - Data splitting and saving completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define paths and parameters\n",
    "full_json = path_home + '/data/dataset_full.json'\n",
    "train_json = full_json\n",
    "\n",
    "logger.info(f\"Loading data from {full_json} for splitting into train/test subsets.\")\n",
    "\n",
    "# Split into train/test subsets\n",
    "train_df, test_df = split.split_train_test(train_json, train_ratio, seed=seed)\n",
    "\n",
    "train_json = f\"{path_raw_data}/train_data.json\"\n",
    "test_json = f\"{path_raw_data}/test_data.json\"\n",
    "\n",
    "logger.info(f\"Saving training data to {train_json}.\")\n",
    "split.save_json_dataset(train_df, train_json)\n",
    "\n",
    "logger.info(f\"Saving testing data to {test_json}.\")\n",
    "split.save_json_dataset(test_df, test_json)\n",
    "\n",
    "logger.info(\"Printing class distribution for training and testing datasets.\")\n",
    "split.print_class_distribution(train_df, \"Train\")\n",
    "split.print_class_distribution(test_df, \"Test\")\n",
    "\n",
    "logger.info(\"Data splitting and saving completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export MKL_SERVICE_FORCE_INTEL=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 11:46:40,936 - INFO - Creating directories for test files: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/cnn_classifier json with size: 10000\n",
      "2024-11-08 11:46:40,937 - INFO - Generating subset data from /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images/test_data.json with size 10000 and seed 42\n",
      "2024-11-08 11:46:40,937 - INFO - Creating subset from /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images/train_data.json with size: 10000\n",
      "Subsetting classes: 100%|██████████| 10/10 [00:00<00:00, 2298.75class/s]\n",
      "2024-11-08 11:46:40,988 - INFO - Subset creation completed with 10000 total samples.\n",
      "2024-11-08 11:46:40,990 - INFO - Subset DataFrame created. Path raw data: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images, Path classifier data: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/cnn_classifier/data\n",
      "2024-11-08 11:46:40,990 - INFO - Copying images from /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images to /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/cnn_classifier/data\n"
     ]
    }
   ],
   "source": [
    "# train MLP/CNN classifier, test for benchmark using test_imgs.py\n",
    "test_json = test_json\n",
    "test_size = 10000\n",
    "\n",
    "\n",
    "logger.info(f\"Creating directories for test files: {path_cnn_classifier} json with size: {test_size}\")\n",
    "# _, _, path_model_images = split.open_folders(model_name, path_cnn_classifier)\n",
    "path_classifier_data = path_cnn_classifier +\"/data\"\n",
    "os.makedirs(path_cnn_classifier, exist_ok=True)\n",
    "os.makedirs(path_classifier_data, exist_ok=True)\n",
    "\n",
    "\n",
    "logger.info(f\"Generating subset data from {test_json} with size {test_size} and seed {seed}\")\n",
    "subset_df = split.subset_data(train_json, test_size, seed)\n",
    "# print(len(subset_df))\n",
    "# subset_df\n",
    "\n",
    "\n",
    "logger.info(f\"Subset DataFrame created. Path raw data: {path_raw_data}, Path classifier data: {path_classifier_data}\")\n",
    "split.copy_images_to_model_and_dataset(subset_df, path_raw_data, path_classifier_data)\n",
    "\n",
    "# logger.info(f\"Saving subset data to {path_subset_json}\")\n",
    "# split.save_json_dataset(subset_df, path_subset_json)\n",
    "\n",
    "# logger.info(f\"Distributing files into label directories at {path_model_images}\")\n",
    "# split.distribute_files_to_label_dirs(path_model_images)\n",
    "\n",
    "# logger.info(\"Generating labels JSON for the subset.\")\n",
    "# split.generate_labels_json(path_model_images, path_model_images, \"dataset.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_json = path_raw_data + '/train_data.json'\n",
    "path_curr_run = os.path.join(path_models, 'run_' + datetime.now().strftime('%Y%m%d_%H-%M'))\n",
    "# train_sizes = [40000]\n",
    "\n",
    "for train_size in train_sizes:\n",
    "    # Create a name for the subset and the model\n",
    "    model_name = f\"model_{train_size}_{datetime.now().strftime('%Y%m%d_%H-%M')}\"\n",
    "    path_model = os.path.join(path_curr_run, model_name)\n",
    "    path_experiments = os.path.join(path_model, 'experiments')\n",
    "    path_dataset = os.path.join(path_model, 'dataset')\n",
    "    path_subset_json = f\"{path_model}/dataset_subset_size_{train_size}_seed_{seed}.json\"\n",
    "    \n",
    "    logger.info(f\"Creating directories for model: {model_name}\")\n",
    "    _, _, path_model_images = split.open_folders(model_name, path_model)\n",
    "    \n",
    "    logger.info(f\"Generating subset data from {train_json} with size {train_size} and seed {seed}\")\n",
    "    subset_df = split.subset_data(train_json, train_size, seed)\n",
    "    \n",
    "    logger.info(f\"Subset DataFrame created. Path raw data: {path_raw_data}, Path model images: {path_model_images}\")\n",
    "    split.copy_images_to_model_and_dataset(subset_df, path_raw_data, path_model_images)\n",
    "    \n",
    "    logger.info(f\"Saving subset data to {path_subset_json}\")\n",
    "    split.save_json_dataset(subset_df, path_subset_json)\n",
    "\n",
    "    logger.info(f\"Distributing files into label directories at {path_model_images}\")\n",
    "    split.distribute_files_to_label_dirs(path_model_images)\n",
    "    \n",
    "    logger.info(\"Generating labels JSON for the subset.\")\n",
    "    split.generate_labels_json(path_model_images, path_model_images, \"dataset.json\")\n",
    "    \n",
    "    logger.info(f\"Creating dataset for {model_name}...\")\n",
    "    train_model.create_dataset(path_home, path_model_images, path_dataset)\n",
    "\n",
    "    logger.info(f\"Training model {model_name}...\")\n",
    "    train_model.run_stylegan_training(path_home, path_experiments, path_dataset, snap=10, kimg=kimg)\n",
    "    \n",
    "    logger.info(f\"Cleaning up model directories for {model_name}\")\n",
    "    # split.delete_images_and_dataset_dirs(path_model)\n",
    "\n",
    "        \n",
    "        # train the classifier\n",
    "        # split the training step and the gen steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_curr_run = os.path.join(path_models, 'run_' + datetime.now().strftime('%Y%m%d_%H-%M'))\n",
    "path_curr_run = '/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models'\n",
    "\n",
    "for entry in os.scandir(path_curr_run):\n",
    "    if entry.is_dir() and 'model' in str(entry.name):\n",
    "        print(entry.name)\n",
    "        path_model = entry\n",
    "        path_latest_pkl_file = split.get_latest_pkl_file(path_model)\n",
    "        if path_latest_pkl_file:\n",
    "            logger.info(f\"Most recent .pkl file: {path_latest_pkl_file}\")\n",
    "            for gen_size in gen_sizes:\n",
    "                gen_size = gen_size // 10\n",
    "                path_generations = os.path.join(path_model, 'generations_'+ str(gen_size * 10))\n",
    "                logger.info(f\"Generating synthetic images for {entry.name} with generation size {gen_size * 10}...\")\n",
    "                train_model.generate_stylegan_images(path_home, path_latest_pkl_file, path_generations, f\"0-{gen_size}\")\n",
    "        else:\n",
    "            logger.warning(\"No .pkl file found for generation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_curr_run = os.path.join(path_models, 'run_' + datetime.now().strftime('%Y%m%d_%H-%M'))\n",
    "path_curr_run = '/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/models'\n",
    "\n",
    "for entry in os.scandir(path_curr_run):\n",
    "    if entry.is_dir() and 'model' in str(entry.name):\n",
    "        print(entry.name)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results - relevant metric: avg/class accuracy, f1, precision, recall, AUC-ROC...\n",
    "# graph/tabular\n",
    "logging.shutdown()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
