{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms.v2\n",
    "from PIL import Image\n",
    "import ipynbname\n",
    "import json\n",
    "import shutil\n",
    "import split_dataset as split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_home = \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation\"\n",
    "raw_data = path_home + \"/data/mnist_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories to save MNIST images\n",
    "mnist_dir = raw_data\n",
    "os.makedirs(mnist_dir, exist_ok=True)\n",
    "\n",
    "# Download MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    # transforms.Grayscale(num_output_channels=1),  # In case the images are not grayscale\n",
    "    transforms.v2.RGB(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "mnist_dataset = datasets.MNIST(root='data', train=True, transform=transform, download=True)\n",
    "\n",
    "# Save each image as a separate file\n",
    "for idx, (img, label) in enumerate(mnist_dataset):\n",
    "    img_path = os.path.join(mnist_dir, f'{label}_{idx}.png')\n",
    "    img = transforms.ToPILImage()(img)\n",
    "    img.save(img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977fb4ef8c254b33bdbd9e4e8f1ce749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing files:   0%|          | 0/60000 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 12000/60000 files...\n",
      "Processed 24000/60000 files...\n",
      "Processed 36000/60000 files...\n",
      "Processed 48000/60000 files...\n",
      "Processed 60000/60000 files...\n",
      "\n",
      "Processing complete. Summary:\n",
      "Total files processed: 60000\n",
      "Consistent files: 60000\n",
      "Files with inconsistent size: 0\n",
      "Files with inconsistent color format: 0\n",
      "Base size: (32, 32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test all files in path_img for size and format:\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "from PIL import Image   \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "IMAGE_PATH = raw_data\n",
    "files = [f for f in listdir(IMAGE_PATH) if isfile(join(IMAGE_PATH, f))]\n",
    "\n",
    "base_size = None\n",
    "consistent_files = 0\n",
    "inconsistent_size_files = 0\n",
    "inconsistent_color_files = 0\n",
    "total_files = len(files)\n",
    "\n",
    "# Set the interval for status updates (e.g., every 100 files)\n",
    "update_interval = int(total_files/5)\n",
    "\n",
    "# Create a progress bar\n",
    "progress_bar = tqdm(total=total_files, desc=\"Processing files\", unit=\"file\")\n",
    "\n",
    "for i, file in enumerate(files, 1):\n",
    "    file_path = os.path.join(IMAGE_PATH, file)\n",
    "    img = Image.open(file_path)\n",
    "    sz = img.size\n",
    "    \n",
    "    if base_size is None:\n",
    "        base_size = sz\n",
    "    \n",
    "    if sz != base_size:\n",
    "        inconsistent_size_files += 1\n",
    "    elif img.mode != 'RGB':\n",
    "        inconsistent_color_files += 1\n",
    "    else:\n",
    "        consistent_files += 1\n",
    "    \n",
    "    # Update the progress bar\n",
    "    progress_bar.update(1)\n",
    "    \n",
    "    # Print status update every x files\n",
    "    if i % update_interval == 0:\n",
    "        print(f\"Processed {i}/{total_files} files...\")\n",
    "\n",
    "# Close the progress bar\n",
    "progress_bar.close()\n",
    "\n",
    "# Print completion stats\n",
    "print(\"\\nProcessing complete. Summary:\")\n",
    "print(f\"Total files processed: {total_files}\")\n",
    "print(f\"Consistent files: {consistent_files}\")\n",
    "print(f\"Files with inconsistent size: {inconsistent_size_files}\")\n",
    "print(f\"Files with inconsistent color format: {inconsistent_color_files}\")\n",
    "print(f\"Base size: {base_size}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'split_dataset' has no attribute 'distribute_files_to_label_dirs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 24\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# divide into subdirectories\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# def distribute_files(src_dir):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#                 # Handle files that don't follow the expected naming convention\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#                 print(f\"Skipping file: {filename} (doesn't follow the expected naming convention)\")\u001b[39;00m\n\u001b[1;32m     23\u001b[0m source_directory \u001b[38;5;241m=\u001b[39m raw_data\n\u001b[0;32m---> 24\u001b[0m \u001b[43msplit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_files_to_label_dirs\u001b[49m(source_directory)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'split_dataset' has no attribute 'distribute_files_to_label_dirs'"
     ]
    }
   ],
   "source": [
    "# divide into subdirectories\n",
    "\n",
    "# def distribute_files(src_dir):\n",
    "#     # Create class directories if they don't exist\n",
    "#     for class_num in range(10):\n",
    "#         class_dir = os.path.join(src_dir, f\"{class_num}\")\n",
    "#         if not os.path.exists(class_dir):\n",
    "#             os.makedirs(class_dir)\n",
    "\n",
    "#     # Distribute files into their respective class directories\n",
    "#     for filename in os.listdir(src_dir):\n",
    "#         src_path = os.path.join(src_dir, filename)\n",
    "#         if os.path.isfile(src_path):\n",
    "#             try:\n",
    "#                 file_class = filename.split(\"_\")[0][0]\n",
    "#                 if file_class.isdigit():\n",
    "#                     dst_path = os.path.join(src_dir, f\"{file_class}\", filename)\n",
    "#                     shutil.move(src_path, dst_path)\n",
    "#             except (IndexError, ValueError):\n",
    "#                 # Handle files that don't follow the expected naming convention\n",
    "#                 print(f\"Skipping file: {filename} (doesn't follow the expected naming convention)\")\n",
    "\n",
    "source_directory = raw_data\n",
    "split.distribute_files_to_label_dirs(source_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to generate labels JSON file...\n",
      "Base directory: /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/data/mnist_images\n"
     ]
    }
   ],
   "source": [
    "# # Create initial dataset.json file from raw dataset:\n",
    "\n",
    "# # {\n",
    "# #     \"labels\":\n",
    "# #         [\n",
    "# #             [\"folder1/1.jpg\", 0], [\"folder1/2.jpg\", 0], [\"folder1/3.jpg\", 0], \n",
    "# #             [\"folder2/4.jpg\", 1], [\"folder2/5.jpg\", 1], [\"folder2/6.jpg\", 1], \n",
    "# #             [\"folder3/7.jpg\", 2], [\"folder3/8.jpg\", 2], [\"folder3/9.jpg\", 2], \n",
    "# #         ]\n",
    "# # }\n",
    "\n",
    "# def generate_labels_json(base_dir,output_dir, output_file_name):\n",
    "#     print(f\"Starting to generate labels JSON file...\")\n",
    "#     print(f\"Base directory: {base_dir}\")\n",
    "\n",
    "#     labels_data = {\"labels\": []}\n",
    "    \n",
    "#     # Walk through the base directory and its subdirectories\n",
    "#     for root, dirs, files in os.walk(base_dir):\n",
    "#         for file in files:\n",
    "#             # Only include image files (you can adjust this based on file extensions)\n",
    "#             if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')):\n",
    "#                 # Extract the class label from the first digit of the file name\n",
    "#                 try:\n",
    "#                     label = int(file[0])  # First digit of the file name\n",
    "#                 except ValueError:\n",
    "#                     # Skip files that do not start with a digit\n",
    "#                     continue\n",
    "                \n",
    "#                 # Create relative file path from the base directory\n",
    "#                 file_path = os.path.relpath(os.path.join(root, file), base_dir)\n",
    "                \n",
    "#                 # Add the file path and corresponding label to the list\n",
    "#                 labels_data[\"labels\"].append([file_path, label])\n",
    "\n",
    "\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "#     output_file_path = os.path.join(output_dir, output_file_name)\n",
    "\n",
    "#     # Write the labels to the output JSON file\n",
    "#     with open(output_file_path, 'w') as f:\n",
    "#         json.dump(labels_data, f, indent=4)\n",
    "\n",
    "# base_directory = raw_data\n",
    "# generate_labels_json(base_directory, base_directory, \"dataset.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to generate labels JSON file...\n",
      "Base directory: /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/data/mnist_images\n",
      "Processed 10000 files...\n",
      "Processed 20000 files...\n",
      "Processed 30000 files...\n",
      "Processed 40000 files...\n",
      "Processed 50000 files...\n",
      "Processed 60000 files...\n",
      "Generated labels JSON file with 60000 entries.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Create initial dataset.json file from raw dataset:\n",
    "\n",
    "base_directory = raw_data\n",
    "# base_directory = '/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/models/model_0K/images'\n",
    "split.generate_labels_json(base_directory, path_home + '/data', \"dataset_full.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
