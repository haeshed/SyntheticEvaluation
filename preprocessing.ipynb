{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms\n",
    "from PIL import Image\n",
    "import json\n",
    "import shutil\n",
    "import split_dataset as split\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "from PIL import Image   \n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.1\n",
      "1.8.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_home = '/home/pathorad3090/Documents/Hadar/SyntheticEvaluation'\n",
    "raw_data = path_home + \"/data/mnist_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 6927456.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 187703.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1571950.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 1007484.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "to_rgb = transforms.Lambda(lambda img: img.convert('RGB'))\n",
    "# rgb_image = to_rgb(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e29c7674dd4bdb80f53e6e237db4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create directories to save MNIST images\n",
    "mnist_dir = raw_data\n",
    "os.makedirs(mnist_dir, exist_ok=True)\n",
    "\n",
    "# Download MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    # transforms.RGB(),\n",
    "    to_rgb,\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "mnist_dataset = datasets.MNIST(root='data', train=True, transform=transform, download=True)\n",
    "\n",
    "# Save each image as a separate file\n",
    "for idx, (img, label) in tqdm(enumerate(mnist_dataset), total=len(mnist_dataset)):\n",
    "    img_path = os.path.join(mnist_dir, f'{label}_{idx}.png')\n",
    "    img = transforms.ToPILImage()(img)\n",
    "    img.save(img_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc8dd7d4db045f3b1d30a7b06ab8f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing files:   0%|          | 0/60000 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 12000/60000 files...\n",
      "Processed 24000/60000 files...\n",
      "Processed 36000/60000 files...\n",
      "Processed 48000/60000 files...\n",
      "Processed 60000/60000 files...\n",
      "\n",
      "Processing complete. Summary:\n",
      "Total files processed: 60000\n",
      "Consistent files: 60000\n",
      "Files with inconsistent size: 0\n",
      "Files with inconsistent color format: 0\n",
      "Base size: (32, 32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# raw_data = path_home + \"/data/rgbs\"\n",
    "\n",
    "\n",
    "IMAGE_PATH = raw_data\n",
    "print(IMAGE_PATH)\n",
    "files = [f for f in listdir(IMAGE_PATH) if isfile(join(IMAGE_PATH, f))]\n",
    "\n",
    "base_size = None\n",
    "consistent_files = 0\n",
    "inconsistent_size_files = 0\n",
    "inconsistent_color_files = 0\n",
    "total_files = len(files)\n",
    "\n",
    "# Set the interval for status updates (e.g., every 100 files)\n",
    "update_interval = int(total_files/5)\n",
    "\n",
    "# Create a progress bar\n",
    "progress_bar = tqdm(total=total_files, desc=\"Processing files\", unit=\"file\")\n",
    "\n",
    "for i, file in enumerate(files, 1):\n",
    "    file_path = os.path.join(IMAGE_PATH, file)\n",
    "    img = Image.open(file_path)\n",
    "    sz = img.size\n",
    "    \n",
    "    if base_size is None:\n",
    "        base_size = sz\n",
    "    \n",
    "    if sz != base_size:\n",
    "        inconsistent_size_files += 1\n",
    "    elif img.mode != 'RGB':\n",
    "        inconsistent_color_files += 1\n",
    "    else:\n",
    "        consistent_files += 1\n",
    "    \n",
    "    # Update the progress bar\n",
    "    progress_bar.update(1)\n",
    "    \n",
    "    # Print status update every x files\n",
    "    if i % update_interval == 0:\n",
    "        print(f\"Processed {i}/{total_files} files...\")\n",
    "\n",
    "# Close the progress bar\n",
    "progress_bar.close()\n",
    "\n",
    "# Print completion stats\n",
    "print(\"\\nProcessing complete. Summary:\")\n",
    "print(f\"Total files processed: {total_files}\")\n",
    "print(f\"Consistent files: {consistent_files}\")\n",
    "print(f\"Files with inconsistent size: {inconsistent_size_files}\")\n",
    "print(f\"Files with inconsistent color format: {inconsistent_color_files}\")\n",
    "print(f\"Base size: {base_size}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the color mode of 1 of the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide into subdirectories\n",
    "\n",
    "# def distribute_files(src_dir):\n",
    "#     # Create class directories if they don't exist\n",
    "#     for class_num in range(10):\n",
    "#         class_dir = os.path.join(src_dir, f\"{class_num}\")\n",
    "#         if not os.path.exists(class_dir):\n",
    "#             os.makedirs(class_dir)\n",
    "\n",
    "#     # Distribute files into their respective class directories\n",
    "#     for filename in os.listdir(src_dir):\n",
    "#         src_path = os.path.join(src_dir, filename)\n",
    "#         if os.path.isfile(src_path):\n",
    "#             try:\n",
    "#                 file_class = filename.split(\"_\")[0][0]\n",
    "#                 if file_class.isdigit():\n",
    "#                     dst_path = os.path.join(src_dir, f\"{file_class}\", filename)\n",
    "#                     shutil.move(src_path, dst_path)\n",
    "#             except (IndexError, ValueError):\n",
    "#                 # Handle files that don't follow the expected naming convention\n",
    "#                 print(f\"Skipping file: {filename} (doesn't follow the expected naming convention)\")\n",
    "\n",
    "source_directory = raw_data\n",
    "split.distribute_files_to_label_dirs(source_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create initial dataset.json file from raw dataset:\n",
    "\n",
    "# # {\n",
    "# #     \"labels\":\n",
    "# #         [\n",
    "# #             [\"folder1/1.jpg\", 0], [\"folder1/2.jpg\", 0], [\"folder1/3.jpg\", 0], \n",
    "# #             [\"folder2/4.jpg\", 1], [\"folder2/5.jpg\", 1], [\"folder2/6.jpg\", 1], \n",
    "# #             [\"folder3/7.jpg\", 2], [\"folder3/8.jpg\", 2], [\"folder3/9.jpg\", 2], \n",
    "# #         ]\n",
    "# # }\n",
    "\n",
    "# def generate_labels_json(base_dir,output_dir, output_file_name):\n",
    "#     print(f\"Starting to generate labels JSON file...\")\n",
    "#     print(f\"Base directory: {base_dir}\")\n",
    "\n",
    "#     labels_data = {\"labels\": []}\n",
    "    \n",
    "#     # Walk through the base directory and its subdirectories\n",
    "#     for root, dirs, files in os.walk(base_dir):\n",
    "#         for file in files:\n",
    "#             # Only include image files (you can adjust this based on file extensions)\n",
    "#             if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')):\n",
    "#                 # Extract the class label from the first digit of the file name\n",
    "#                 try:\n",
    "#                     label = int(file[0])  # First digit of the file name\n",
    "#                 except ValueError:\n",
    "#                     # Skip files that do not start with a digit\n",
    "#                     continue\n",
    "                \n",
    "#                 # Create relative file path from the base directory\n",
    "#                 file_path = os.path.relpath(os.path.join(root, file), base_dir)\n",
    "                \n",
    "#                 # Add the file path and corresponding label to the list\n",
    "#                 labels_data[\"labels\"].append([file_path, label])\n",
    "\n",
    "\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "#     output_file_path = os.path.join(output_dir, output_file_name)\n",
    "\n",
    "#     # Write the labels to the output JSON file\n",
    "#     with open(output_file_path, 'w') as f:\n",
    "#         json.dump(labels_data, f, indent=4)\n",
    "\n",
    "# base_directory = raw_data\n",
    "# generate_labels_json(base_directory, base_directory, \"dataset.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to generate labels JSON file...\n",
      "Base directory: /home/pathorad3090/Documents/Hadar/SyntheticEvaluation/data/mnist_images\n",
      "Processed 10000 files...\n",
      "Processed 20000 files...\n",
      "Processed 30000 files...\n",
      "Processed 40000 files...\n",
      "Processed 50000 files...\n",
      "Processed 60000 files...\n",
      "Generated labels JSON file with 60000 entries.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Create initial dataset.json file from raw dataset:\n",
    "\n",
    "base_directory = raw_data\n",
    "# base_directory = '/Users/hadare/Documents/CodingProjects/SyntheticEvaluation/models/model_0K/images'\n",
    "split.generate_labels_json(base_directory, path_home + '/data', \"dataset_full.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
