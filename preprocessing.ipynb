{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms.v2\n",
    "from PIL import Image\n",
    "import ipynbname\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_home = \"/Users/hadare/Documents/CodingProjects/SyntheticEvaluation\"\n",
    "path_img =  path_home + \"/images\"\n",
    "path_dataset = path_home + \"/dataset\"\n",
    "path_exp = path_home + \"/experiments\"\n",
    "raw_data = path_home + \"/data/mnist_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:04<00:00, 2465210.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 187442.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:04<00:00, 349873.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 1126184.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create directories to save MNIST images\n",
    "mnist_dir = raw_data\n",
    "os.makedirs(mnist_dir, exist_ok=True)\n",
    "\n",
    "# Download MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    # transforms.Grayscale(num_output_channels=1),  # In case the images are not grayscale\n",
    "    transforms.v2.RGB(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "mnist_dataset = datasets.MNIST(root='data', train=True, transform=transform, download=True)\n",
    "\n",
    "# Save each image as a separate file\n",
    "for idx, (img, label) in enumerate(mnist_dataset):\n",
    "    img_path = os.path.join(mnist_dir, f'{label}_{idx}.png')\n",
    "    img = transforms.ToPILImage()(img)\n",
    "    img.save(img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35904f15b7a41e1884fc798a2512866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing files:   0%|          | 0/60000 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 12000/60000 files...\n",
      "Processed 24000/60000 files...\n",
      "Processed 36000/60000 files...\n",
      "Processed 48000/60000 files...\n",
      "Processed 60000/60000 files...\n",
      "\n",
      "Processing complete. Summary:\n",
      "Total files processed: 60000\n",
      "Consistent files: 60000\n",
      "Files with inconsistent size: 0\n",
      "Files with inconsistent color format: 0\n",
      "Base size: (32, 32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test all files in path_img for size and format:\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "from PIL import Image   \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "IMAGE_PATH = raw_data\n",
    "files = [f for f in listdir(IMAGE_PATH) if isfile(join(IMAGE_PATH, f))]\n",
    "\n",
    "base_size = None\n",
    "consistent_files = 0\n",
    "inconsistent_size_files = 0\n",
    "inconsistent_color_files = 0\n",
    "total_files = len(files)\n",
    "\n",
    "# Set the interval for status updates (e.g., every 100 files)\n",
    "update_interval = int(total_files/5)\n",
    "\n",
    "# Create a progress bar\n",
    "progress_bar = tqdm(total=total_files, desc=\"Processing files\", unit=\"file\")\n",
    "\n",
    "for i, file in enumerate(files, 1):\n",
    "    file_path = os.path.join(IMAGE_PATH, file)\n",
    "    img = Image.open(file_path)\n",
    "    sz = img.size\n",
    "    \n",
    "    if base_size is None:\n",
    "        base_size = sz\n",
    "    \n",
    "    if sz != base_size:\n",
    "        inconsistent_size_files += 1\n",
    "    elif img.mode != 'RGB':\n",
    "        inconsistent_color_files += 1\n",
    "    else:\n",
    "        consistent_files += 1\n",
    "    \n",
    "    # Update the progress bar\n",
    "    progress_bar.update(1)\n",
    "    \n",
    "    # Print status update every x files\n",
    "    if i % update_interval == 0:\n",
    "        print(f\"Processed {i}/{total_files} files...\")\n",
    "\n",
    "# Close the progress bar\n",
    "progress_bar.close()\n",
    "\n",
    "# Print completion stats\n",
    "print(\"\\nProcessing complete. Summary:\")\n",
    "print(f\"Total files processed: {total_files}\")\n",
    "print(f\"Consistent files: {consistent_files}\")\n",
    "print(f\"Files with inconsistent size: {inconsistent_size_files}\")\n",
    "print(f\"Files with inconsistent color format: {inconsistent_color_files}\")\n",
    "print(f\"Base size: {base_size}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide into subdirectories\n",
    "\n",
    "def distribute_files(src_dir):\n",
    "    # Create class directories if they don't exist\n",
    "    for class_num in range(10):\n",
    "        class_dir = os.path.join(src_dir, f\"class_{class_num}\")\n",
    "        if not os.path.exists(class_dir):\n",
    "            os.makedirs(class_dir)\n",
    "\n",
    "    # Distribute files into their respective class directories\n",
    "    for filename in os.listdir(src_dir):\n",
    "        src_path = os.path.join(src_dir, filename)\n",
    "        if os.path.isfile(src_path):\n",
    "            try:\n",
    "                file_class = filename.split(\"_\")[0][0]\n",
    "                if file_class.isdigit():\n",
    "                    dst_path = os.path.join(src_dir, f\"class_{file_class}\", filename)\n",
    "                    shutil.move(src_path, dst_path)\n",
    "            except (IndexError, ValueError):\n",
    "                # Handle files that don't follow the expected naming convention\n",
    "                print(f\"Skipping file: {filename} (doesn't follow the expected naming convention)\")\n",
    "\n",
    "source_directory = raw_data\n",
    "distribute_files(source_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to generate labels JSON file...\n",
      "Base directory: /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/data/mnist_images\n"
     ]
    }
   ],
   "source": [
    "# Create initial dataset.json file from raw dataset:\n",
    "\n",
    "# {\n",
    "#     \"labels\":\n",
    "#         [\n",
    "#             [\"folder1/1.jpg\", 0], [\"folder1/2.jpg\", 0], [\"folder1/3.jpg\", 0], \n",
    "#             [\"folder2/4.jpg\", 1], [\"folder2/5.jpg\", 1], [\"folder2/6.jpg\", 1], \n",
    "#             [\"folder3/7.jpg\", 2], [\"folder3/8.jpg\", 2], [\"folder3/9.jpg\", 2], \n",
    "#         ]\n",
    "# }\n",
    "\n",
    "def generate_labels_json(base_dir,output_dir, output_file_name):\n",
    "    print(f\"Starting to generate labels JSON file...\")\n",
    "    print(f\"Base directory: {base_dir}\")\n",
    "\n",
    "    labels_data = {\"labels\": []}\n",
    "    \n",
    "    # Walk through the base directory and its subdirectories\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            # Only include image files (you can adjust this based on file extensions)\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')):\n",
    "                # Extract the class label from the first digit of the file name\n",
    "                try:\n",
    "                    label = int(file[0])  # First digit of the file name\n",
    "                except ValueError:\n",
    "                    # Skip files that do not start with a digit\n",
    "                    continue\n",
    "                \n",
    "                # Create relative file path from the base directory\n",
    "                file_path = os.path.relpath(os.path.join(root, file), base_dir)\n",
    "                \n",
    "                # Add the file path and corresponding label to the list\n",
    "                labels_data[\"labels\"].append([file_path, label])\n",
    "\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file_path = os.path.join(output_dir, output_file_name)\n",
    "\n",
    "    # Write the labels to the output JSON file\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        json.dump(labels_data, f, indent=4)\n",
    "\n",
    "base_directory = raw_data\n",
    "generate_labels_json(base_directory, base_directory, \"dataset.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to generate labels JSON file...\n",
      "Base directory: /Users/hadare/Documents/CodingProjects/SyntheticEvaluation/data/mnist_images\n",
      "Processed 10000 files...\n",
      "Processed 20000 files...\n",
      "Processed 30000 files...\n",
      "Processed 40000 files...\n",
      "Processed 50000 files...\n",
      "Processed 60000 files...\n",
      "Generated labels JSON file with 60000 entries.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Create initial dataset.json file from raw dataset:\n",
    "\n",
    "# {\n",
    "#     \"labels\":\n",
    "#         [\n",
    "#             [\"folder1/1.jpg\", 0], [\"folder1/2.jpg\", 0], [\"folder1/3.jpg\", 0], \n",
    "#             [\"folder2/4.jpg\", 1], [\"folder2/5.jpg\", 1], [\"folder2/6.jpg\", 1], \n",
    "#             [\"folder3/7.jpg\", 2], [\"folder3/8.jpg\", 2], [\"folder3/9.jpg\", 2], \n",
    "#         ]\n",
    "# }\n",
    "\n",
    "def generate_labels_json(base_dir, output_dir, output_file_name):\n",
    "    print(f\"Starting to generate labels JSON file...\")\n",
    "    print(f\"Base directory: {base_dir}\")\n",
    "\n",
    "    labels_data = {\"labels\": []}\n",
    "    file_count = 0\n",
    "\n",
    "    # Walk through the base directory and its subdirectories\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            # Only include image files (you can adjust this based on file extensions)\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')):\n",
    "                # Extract the class label from the first digit of the file name\n",
    "                try:\n",
    "                    label = int(file[0])  # First digit of the file name\n",
    "                except ValueError:\n",
    "                    # Skip files that do not start with a digit\n",
    "                    continue\n",
    "\n",
    "                # Create relative file path from the base directory\n",
    "                file_path = os.path.relpath(os.path.join(root, file), base_dir)\n",
    "\n",
    "                # Add the file path and corresponding label to the list\n",
    "                labels_data[\"labels\"].append([file_path, label])\n",
    "                file_count += 1\n",
    "\n",
    "            # Print progress after every 1000 files\n",
    "                if file_count % 10000 == 0:\n",
    "                    print(f\"Processed {file_count} files...\")\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_file_path = os.path.join(output_dir, output_file_name)\n",
    "\n",
    "    # Write the labels to the output JSON file\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        json.dump(labels_data, f, indent=4)\n",
    "\n",
    "    print(f\"Generated labels JSON file with {len(labels_data['labels'])} entries.\")\n",
    "\n",
    "base_directory = raw_data\n",
    "generate_labels_json(base_directory, base_directory, \"dataset.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
